{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d7f8e58",
   "metadata": {},
   "source": [
    "# Regularization in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3e8b9d",
   "metadata": {},
   "source": [
    "\n",
    "Regularization is a key concept in machine learning used to prevent overfitting by introducing additional information or constraints to a model. \n",
    "This notebook explores different regularization methods and their implementation in **Vanilla Python** and **PyTorch**.\n",
    "    \n",
    "Topics Covered:\n",
    "1. L2 Regularization (Ridge)\n",
    "2. Dropout\n",
    "3. Weight Decay\n",
    "4. Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cadc606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71496168",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_URL='https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true'\n",
    "path_data = Path('data')\n",
    "path_data.mkdir(exist_ok=True)\n",
    "path_gz = path_data/'mnist.pkl.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a9293db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "if not path_gz.exists(): urlretrieve(MNIST_URL, path_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b86a9ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with gzip.open(path_gz, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "        \n",
    "    x_train, y_train, x_valid, y_valid = map(lambda x: torch.from_numpy(x).float(),\n",
    "                                             (x_train, y_train, x_valid, y_valid))\n",
    "    \n",
    "    return (x_train, y_train, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04d91809",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1e6fa88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c7b71",
   "metadata": {},
   "source": [
    "# No Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5e24e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "        nn.Linear(784, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 10),\n",
    "        nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57512738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x, y, criterion, optimizer, epochs=500):\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        preds = model(x)\n",
    "        loss = criterion(preds, y.long())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch == 1: print(loss)\n",
    "        if epoch % 100 == 0: print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44584029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(model, x, y):\n",
    "    \n",
    "    model.eval() \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad(): \n",
    "\n",
    "        outputs = model(x)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item() \n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e223872",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c532e6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = load_data()\n",
    "small_x_train = x_train[:10000]\n",
    "small_y_train = y_train[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30eb954b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3022, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2453, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2836, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2490, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2457, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2451, grad_fn=<NllLossBackward0>)\n",
      "CPU times: user 51.2 s, sys: 2min 9s, total: 3min\n",
      "Wall time: 19.1 s\n"
     ]
    }
   ],
   "source": [
    "%time train(model, x_train, y_train, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f1895d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.72999999999999"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_acc(model, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f36df1",
   "metadata": {},
   "source": [
    "Adding lambda * vector norm ^2 to the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b7ce96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_reg = 0.001\n",
    "loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8b68b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_loss = sum(torch.norm(param) ** 2 for param in model.parameters())\n",
    "total_loss = loss + lambda_reg * l2_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0f60d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([3.,4.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9b95d8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "45933bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(3**2 + 4**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88086b34",
   "metadata": {},
   "source": [
    "PyTorch implements l2 through weight decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64963ad6",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Weight Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "64cd8f6c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Network()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4435b808",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bfdfc291",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3083, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1972, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2956, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2461, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2362, grad_fn=<NllLossBackward0>)\n",
      "CPU times: user 51 s, sys: 2min 3s, total: 2min 54s\n",
      "Wall time: 18.6 s\n"
     ]
    }
   ],
   "source": [
    "%time train(model, x_train, y_train, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "fd2352ad",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.33"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_acc(model, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab658ca2",
   "metadata": {
    "hidden": true
   },
   "source": [
    "When should I use what?\n",
    "\n",
    "- If you're using SGD, it doesnt really matter. Use whats easier for u (usually whats supported easier in the framework ure using).\n",
    "- If you're using a smarter optimizer like Adam, use weight decay. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75cbf23",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Why is weight decay prefered over L2 using Adam?\n",
    "\n",
    "Adam adapts the learning rate according to the size of the gradient. L2 changes the gradient directly, which affects how the learning rate in Adam will perform. Weight decay affects the weight change itself, not the gradient, hence Adam will not treat it differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05eaf811",
   "metadata": {
    "hidden": true
   },
   "source": [
    "As adam scales the lr according to the gradient, if the gradient is bigger (because of more L2), the lr will be smaller. In other words, the affect of L2 wont be the same for every weight, but it <b> will </b> be for weight decay."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbefc3e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5b54ed41",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class NetworkWithDropout(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "        nn.Linear(784, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(64, 10),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "7c7ebb1a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = NetworkWithDropout()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b37451c6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fe95feb0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3049, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2832, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2152, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1770, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1625, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1635, grad_fn=<NllLossBackward0>)\n",
      "CPU times: user 1min 13s, sys: 3min 11s, total: 4min 24s\n",
      "Wall time: 28.2 s\n"
     ]
    }
   ],
   "source": [
    "%time train(model, x_train, y_train, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3f1bcef7",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.42"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_acc(model, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adaacbf",
   "metadata": {},
   "source": [
    "# BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f70177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkWithBatchNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "        nn.Linear(784, 128),\n",
    "        nn.BatchNorm1d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.BatchNorm1d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 10),\n",
    "        nn.BatchNorm1d(10),\n",
    "        nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a405453",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NetworkWithBatchNorm()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9ced8211",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd20b88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5129, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.1002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0871, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0060, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0028, grad_fn=<NllLossBackward0>)\n",
      "CPU times: user 1min 12s, sys: 2min 25s, total: 3min 38s\n",
      "Wall time: 23.1 s\n"
     ]
    }
   ],
   "source": [
    "%time train(model, x_train, y_train, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4d02175",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.09"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_acc(model, x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c3eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e708f6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm Layer 1:\n",
      "  Gamma (Scale): tensor([ 1.1652,  0.3029,  0.5780,  0.8863,  2.1060,  0.7894,  1.9146,  0.8595,\n",
      "         1.3479,  2.2594,  0.7499,  1.2502,  0.6055,  0.7897,  1.3201,  1.8231,\n",
      "         0.3432,  1.7832,  1.3496,  1.3438,  0.2845,  1.8903,  1.2405,  1.8726,\n",
      "         1.4783,  0.0918,  0.2287,  1.1246,  0.0831,  0.7382,  1.4862,  1.2834,\n",
      "         1.0800,  0.1879,  1.7311,  0.0501,  0.0605,  0.8945,  0.8620,  1.5843,\n",
      "         0.0808,  1.1216,  1.7470,  0.8454,  1.1101,  1.1589,  0.5654,  1.4216,\n",
      "         1.6013,  2.1777, -0.5968,  1.1514,  0.5874,  1.7584,  1.9480,  1.7042,\n",
      "         2.0037,  1.8315,  2.3074,  1.8558,  0.1167, -0.0719,  0.9678,  1.3273,\n",
      "         0.9043,  0.6597,  1.9749,  1.6451,  1.2883,  1.9117,  2.0002,  1.6170,\n",
      "         0.9194,  2.4162,  1.3838,  0.9666,  0.0900,  2.2153,  1.6092,  1.5673,\n",
      "        -0.9424,  0.8346,  1.6571,  1.2399,  1.3433,  1.3593,  1.7042,  0.0706,\n",
      "         1.2761,  1.4833,  0.1141,  0.7444,  1.4354,  1.4378,  1.5721,  0.0462,\n",
      "         0.9934,  1.9571,  0.7959, -0.0619,  1.2521,  1.9344,  0.9906, -0.6242,\n",
      "         1.3231, -0.1997,  0.7214,  0.0093,  1.2594,  1.1564,  1.3177,  1.1491,\n",
      "         0.6172,  0.2046,  2.2594,  2.2815,  1.4897,  1.0248,  1.8151,  1.2669,\n",
      "         1.9298,  0.9702,  1.3056,  1.3696,  0.1487,  1.5342,  1.3087,  0.4909])\n",
      "BatchNorm Layer 4:\n",
      "  Gamma (Scale): tensor([ 1.4577,  0.6896,  1.2503,  1.8824,  0.8659,  0.0662, -0.9640,  2.2647,\n",
      "         1.5911,  1.5366, -0.0178,  0.7171,  1.3563,  1.1222,  1.2239, -0.0955,\n",
      "         1.8815,  0.5291,  1.9329,  1.3979,  0.7688,  0.8520,  0.2074,  0.6565,\n",
      "         1.0347,  1.3068,  2.0203,  1.7651,  1.8350,  1.5040,  1.2805,  1.1759,\n",
      "         0.6232,  1.1035,  1.1108,  0.8764,  0.0998,  1.9789,  1.3812,  1.4648,\n",
      "         0.4660,  0.4454,  1.2813,  2.0847,  1.8258,  0.4712,  0.6916,  0.2324,\n",
      "         0.9293,  0.5909,  0.6304,  0.9675, -0.0877,  1.9627,  1.8276,  0.6041,\n",
      "         1.3457,  1.5170,  1.9675,  1.7525,  0.9841,  0.5464,  0.3737,  0.7302])\n",
      "BatchNorm Layer 7:\n",
      "  Gamma (Scale): tensor([4.2662, 4.6570, 5.6825, 5.6306, 4.9082, 6.3739, 4.4346, 4.6688, 5.5673,\n",
      "        5.1433])\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.model):\n",
    "    if isinstance(layer, nn.BatchNorm1d):\n",
    "        print(f\"BatchNorm Layer {i}:\")\n",
    "        print(f\"  Gamma (Scale): {layer.weight.data}\")\n",
    "#         print(f\"  Beta (Shift): {layer.bias.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b66f49d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
