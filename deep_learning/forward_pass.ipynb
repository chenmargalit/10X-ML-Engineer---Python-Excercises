{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "427fd138-3086-460e-b973-3ba674b9a2d5",
   "metadata": {},
   "source": [
    "<a href='https://alexlenail.me/NN-SVG/'> NN visualization </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "563bdac1-b02e-4ec6-b3f9-831741675b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a9bbaf1-ee31-4481-8b79-f6a1948c4ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7011d1b-c2db-48c5-a182-84dfdbfd1e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = nn.Linear(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bad7aed-c0ce-4a48-893f-563b5924a87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=2, bias=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c6b5fe0-34f3-46f0-a086-3c394d3eb90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.1524],\n",
       "        [0.5845]], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2850e425-8d6f-4597-b46b-1e22c613cac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.3014, -0.5731], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2b34c9b7-ea8e-47e3-a348-b19b38dae873",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(1, 1)\n",
    "        # self.fc2 = nn.Linear(1,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        # x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe19374-2e46-4791-853f-9796b378e068",
   "metadata": {},
   "source": [
    "fc1 has one neuron. This one neuron receives one input. Neurons hold one weight for each input + one weight for bias (no matter how many inputs). In this case, how many weights and how many biases do we expect to have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5e885ac-24a5-471d-89f3-91374bad8554",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8508239c-3fe1-49fe-9654-b45257d16ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9963a045-c689-41f9-8b22-16eead2fa421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e62cbf7-ac43-4d7b-a060-55229f33d2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0.4469]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0837], requires_grad=True))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc1.weight, n.fc1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "103e3ee2-0b20-47d6-b0f5-ca5586fe4e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3657], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = Network()\n",
    "t = torch.tensor([1], dtype=torch.float32)\n",
    "n(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "95a7a082-1b51-4ec1-81eb-49d84af7e37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4109]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc1.weight.data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0a9d9afc-7d81-4771-a0f8-0d01b6242da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7766])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc1.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d198f0e6-8218-4990-b408-d283dc77daff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4963, -0.1710])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ n.fc1.weight.data.T + n.fc1.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7507eaf-7617-470a-bcc6-ae9ed5c79ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878f4289-8fbe-4ddf-b124-f41e2a7a7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.fc1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1347466-e9e5-44db-9089-eb4d08c5931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.fc1.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d92b5658-ae98-4a50-80e1-faf7dfc51d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(1, 2)\n",
    "        self.fc2 = nn.Linear(2,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b45b587-89aa-4a41-99f1-4b65d63c995d",
   "metadata": {},
   "source": [
    "This time, fc1 has 1 input and two outputs.\n",
    "\n",
    "fc2 has 2 inputs and one input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3bbe3555-560c-496f-9b24-1ba5186fd836",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbeb13c-066c-4e77-b114-27ed5d7de6a9",
   "metadata": {},
   "source": [
    "How many weights and how many biases for fc1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "52169485-bf01-49cf-bb54-159dc9979a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.2275],\n",
       "         [-0.1189]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.9129, -0.7688], requires_grad=True))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc1.weight, n.fc1.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46c99c7-4e31-49f2-93c0-fc3635cb5eea",
   "metadata": {},
   "source": [
    "How many weights and how many biases for fc2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "17e4fd27-dc6e-431c-8e95-39d343bd9d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1]), torch.Size([2]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc1.weight.shape, n.fc1.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "270673e6-4f5a-473e-9b8c-e6ea7c5223da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[-0.0238,  0.0715]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0231], requires_grad=True))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc2.weight, n.fc2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "11101969-7159-4bb2-b5a2-0401e5d3a678",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3031], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = Network()\n",
    "t = torch.tensor([1], dtype=torch.float32)\n",
    "n(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "149326ec-7f67-4fe3-8679-9557acd436d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3031], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_res = n(t)\n",
    "pytorch_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "daacf714-1edf-4001-b829-98fe1abaf513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.5023],\n",
       "         [-0.1162]]),\n",
       " tensor([-0.5331,  0.2996]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc1.weight.data, n.fc1.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "48f52dfa-3dc1-4a61-a44c-043321609971",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1_weights = n.fc1.weight.data\n",
    "fc1_biases = n.fc1.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e2c6c890-8dfc-491e-9ed0-122e057ba7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5331,  0.2996])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0e682f59-cf1f-460c-a659-5186b594a78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0976780f-eb57-4124-9e15-a6b0e9f93841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5023],\n",
       "        [-0.1162]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cb4841c2-4b8a-4ccb-9ed0-66c664af0333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5023, -0.1162])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t @ fc1_weights.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f866c-426a-4178-a74b-f517892417a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(t @ fc1_weights.T) + fc1_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6c8046f7-dec1-44c4-b31d-f759a3ab9574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0354,  0.1834])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1_res = t @ fc1_weights.T + fc1_biases\n",
    "fc1_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b609af2d-6956-43a1-b9dd-4d782bb881fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc2_weight = n.fc2.weight.data\n",
    "fc2_bias = n.fc2.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1e201d48-7cf2-47e4-a6f4-264eac6a34e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0354,  0.1834])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b13e14db-feeb-4070-9360-05e519298245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2647, -0.3894]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc2_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7943817b-88b1-4f45-96fd-59168cc789ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.34548634"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1.0354 * 0.2647 + 0.1834 * -0.3894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0de42b25-458c-44ff-a6f7-939bfe8482aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3455])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1_res @ fc2_weight.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bfaa40be-9f4a-440a-a97b-194b640b424d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0424])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " fc2_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "17d5ad2e-c332-47d6-92c4-b49ae13d7e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3031])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1_res @ fc2_weight.T + fc2_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7680829e-cf33-40ef-ab9c-d2c6ba47db2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3031], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "07b448bc-9303-4291-994a-d64814fd28df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1_res @ fc2_weight.T + fc2_bias == pytorch_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5e1c206c-0ba3-447d-afcd-fcd42253b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(1, 2)\n",
    "        self.fc2 = nn.Linear(2,1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d1562766-5f4e-4988-b490-6ddd0d7b43ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "90a459b8-656d-4464-815f-8ee9eb8642eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([2], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5a571a51-7fcf-4ac6-9631-bb8df5eb0aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0450], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "87e37af4-52ec-444c-bd27-47ef51ea858e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1]), torch.Size([1, 2]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc1.weight.shape, n.fc2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "aa3bb49e-5cb6-4d4f-9558-3e6ccc2fa28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([0.3477, 0.9759], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1724], requires_grad=True))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc1.bias, n.fc2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3ce91dfa-a031-4afe-81eb-15f0a656ad45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2]), torch.Size([1]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc1.bias.shape, n.fc2.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6e6449dd-c9a5-4560-8a76-c46d0e77e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_1 = torch.tensor([[2.,3.]], requires_grad=True)\n",
    "biases_1 = torch.tensor([4., 5.], requires_grad=True)            \n",
    "\n",
    "weights_2 = torch.tensor([[2.], [3.]], requires_grad=True)\n",
    "biases_2 = torch.tensor([4.], requires_grad=True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "552f8164-90ba-4400-877d-3a9c3e861264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1516],\n",
       "        [-0.4170]], requires_grad=True)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cb243f6f-17a6-4a6b-bd71-1c8c6041e580",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.fc1.weight = nn.Parameter(weights_1.T)\n",
    "n.fc1.bias = nn.Parameter(biases_1)\n",
    "\n",
    "n.fc2.weight = nn.Parameter(weights_2.T)\n",
    "n.fc2.bias = nn.Parameter(biases_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b7486ccf-739b-4df9-b3e4-51cd4bdf5ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([53.], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_res = n(t)\n",
    "pytorch_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "09c07613-6856-4b7d-9756-f3e2a35f39d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1]), torch.Size([1, 2]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc1.weight.shape, n.fc2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "de13ef03-c4a3-46e1-bbb0-2e555bf0bd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2]), torch.Size([1]))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc1.bias.shape, n.fc2.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d66135da-b7c4-49f9-a53c-3d32927077d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[2.],\n",
       "        [3.]], requires_grad=True)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5f4df38c-7087-422e-b24b-b622af1c7e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9cccc75d-8061-491e-a9a9-30c077c11038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 6.], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t @ n.fc1.weight.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "18b48110-af2c-40b2-9d00-293d2845c951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([4., 5.], requires_grad=True)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5eec90ad-b3fb-479b-870f-2e61d6cf25f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1_res = t @ n.fc1.weight.T + n.fc1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "edbcb3af-b9ee-45ed-b5cb-953f38ad7c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8., 11.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "627ab49a-0689-4a1e-b571-a46a81bcb145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[2., 3.]], requires_grad=True)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "90a64a12-c299-4aba-a4dd-a17f3cfe867e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2]), torch.Size([1, 2]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1_res.shape, n.fc2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "34516668-ba78-4ad0-9b90-206c8ef56dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8 * 2 + 11 * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9d60fa6f-d2f6-4177-8e4b-d990dd0f43c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([4.], requires_grad=True)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0fa471bc-7383-4f3d-af38-04fe28298cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([49.], grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1_res @ n.fc2.weight.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c52f8a29-d113-4f73-a6f9-0f6464f54abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([4.], requires_grad=True)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.fc2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f351fda3-ab24-46f3-9459-2724fdef01aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([53.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc2_res = fc1_res @ n.fc2.weight.T + n.fc2.bias\n",
    "fc2_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d2e3782d-2212-4263-ba7d-58fda301ac67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc2_res == pytorch_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab6c8c-4440-4ab3-8a04-816c86e88cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all_purpose_venv",
   "language": "python",
   "name": "all_purpose_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
