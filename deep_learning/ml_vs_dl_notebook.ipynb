{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78a72984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67349ca",
   "metadata": {},
   "source": [
    "# Understanding the Difference Between Machine Learning and Deep Learning\n",
    "\n",
    "In this notebook, we will explore the key differences between Machine Learning (ML) and Deep Learning (DL)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bf4a3e",
   "metadata": {},
   "source": [
    "## What is Machine Learning?\n",
    "\n",
    "Machine Learning is a subset of Artificial Intelligence that uses algorithms to learn from data and make decisions or predictions. Traditional ML models often require manual feature engineering to transform raw data into a form that models can use.\n",
    "\n",
    "Common algorithms in machine learning include:\n",
    "- Decision Trees\n",
    "- Random Forest\n",
    "- Logistic Regression\n",
    "- K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac21712",
   "metadata": {},
   "source": [
    "## What is Deep Learning?\n",
    "\n",
    "Deep Learning is a subset of Machine Learning that uses neural networks, particularly multi-layered neural networks (deep neural networks), to automatically learn features from data. It excels in tasks like image recognition, natural language processing, and other complex pattern recognition tasks where manual feature extraction is difficult or inefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c872da85",
   "metadata": {},
   "source": [
    "## Key Differences Between ML and DL\n",
    "\n",
    "| Aspect | Machine Learning | Deep Learning |\n",
    "|--------|------------------|---------------|\n",
    "| Data Processing | Requires manual feature extraction | Automatically extracts features |\n",
    "| Algorithms | Uses classical algorithms like Decision Trees, Linear Regression, etc. | Primarily uses neural networks |\n",
    "| Data Requirements | Works well on smaller datasets | Requires large datasets for good performance |\n",
    "| Computation | Less computationally intensive | Requires more computational power, often using GPUs |\n",
    "| Interpretability | More interpretable | Often referred to as a 'black box' due to its complexity |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34807612",
   "metadata": {},
   "source": [
    "## Practical Example: Machine Learning (Logistic Regression)\n",
    "\n",
    "We will start by implementing a simple logistic regression classifier on a sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19889761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f292f11",
   "metadata": {},
   "source": [
    "## Practical Example: Deep Learning (Feedforward Neural Network)\n",
    "\n",
    "We will implement a simple feedforward neural network using PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "018cda21",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "751e3e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled)\n",
    "y_test_tensor = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e976fbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "262d9bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.6, 3.6, 1. , 0.2])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f4d3767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8bbd0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(4, 16)\n",
    "        self.fc2 = nn.Linear(16, 3)\n",
    "    \n",
    "    def forward(self, x):        \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "627bb7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b1ac7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2146, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1568, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1030, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0520, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9516, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8547, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8077, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7621, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6774, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6392, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5720, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5428, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4925, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4708, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4509, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4327, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4160, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3868, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3737, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3501, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3394, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3294, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2943, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2864, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2788, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2715, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2645, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2576, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2510, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2445, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2382, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2322, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2263, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2205, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2148, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1989, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1939, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1890, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train_tensor)\n",
    "    loss = criterion(output, y_train_tensor)\n",
    "    loss.backward()\n",
    "    if epoch % 10 == 0:\n",
    "        print(loss)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20974123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_output = model(X_test_tensor)\n",
    "    _, predicted = torch.max(test_output, 1)\n",
    "    accuracy = accuracy_score(y_test_tensor, predicted)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b520d3",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We explored the key differences between machine learning and deep learning, including practical implementations of both a traditional machine learning model and a deep learning neural network.\n",
    "\n",
    "- Machine Learning typically involves algorithms such as logistic regression, decision trees, etc., and requires manual feature engineering.\n",
    "- Deep Learning utilizes neural networks, particularly for tasks requiring large datasets and automatic feature extraction.\n",
    "\n",
    "While deep learning has revolutionized certain domains like computer vision and natural language processing, machine learning is still effective and widely used for structured data analysis and simpler tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c340b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66250ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
