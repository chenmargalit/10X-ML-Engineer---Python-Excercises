{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e974c655-4aa9-4bd3-8d06-3fa71781b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data: https://download.pytorch.org/tutorial/data.zip\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from pdb import set_trace\n",
    "import io\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import glob\n",
    "import random\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f1ed62c-2724-4227-be11-0f8e3fa77e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphabet small + capital letters + \" .,;'\"\n",
    "ALL_LETTERS = string.ascii_letters + \" .,;'\"\n",
    "N_LETTERS = len(ALL_LETTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff9c45a4-da1d-498c-b76c-2b17147bb595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in ALL_LETTERS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdf5a94c-afc0-46ba-8165-6ab7af261c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Build the category_lines dictionary, a list of names per language\n",
    "    category_lines = {}\n",
    "    all_categories = []\n",
    "    \n",
    "    def find_files(path):\n",
    "        return glob.glob(path)\n",
    "    \n",
    "    # Read a file and split into lines\n",
    "    def read_lines(filename):\n",
    "        lines = io.open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "        return [unicode_to_ascii(line) for line in lines]\n",
    "    \n",
    "    for filename in find_files('names/*.txt'):\n",
    "        from pdb import set_trace\n",
    "        category = os.path.splitext(os.path.basename(filename))[0]\n",
    "        all_categories.append(category)\n",
    "        \n",
    "        lines = read_lines(filename)\n",
    "        category_lines[category] = lines\n",
    "        \n",
    "    return category_lines, all_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ec884b8-26f9-43c0-a612-d1b83038cc14",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T13:29:55.853104Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTo represent a single letter, we use a “one-hot vector” of \\nsize <1 x n_letters>. A one-hot vector is filled with 0s\\nexcept for a 1 at index of the current letter, e.g. \"b\" = <0 1 0 0 0 ...>.\\n\\nTo make a word we join a bunch of those into a\\n2D matrix <line_length x 1 x n_letters>.\\n\\nThat extra 1 dimension is because PyTorch assumes\\neverything is in batches - we’re just using a batch size of 1 here.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "To represent a single letter, we use a “one-hot vector” of \n",
    "size <1 x n_letters>. A one-hot vector is filled with 0s\n",
    "except for a 1 at index of the current letter, e.g. \"b\" = <0 1 0 0 0 ...>.\n",
    "\n",
    "To make a word we join a bunch of those into a\n",
    "2D matrix <line_length x 1 x n_letters>.\n",
    "\n",
    "That extra 1 dimension is because PyTorch assumes\n",
    "everything is in batches - we’re just using a batch size of 1 here.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5778518-e2ef-48f9-b8bd-a02bd61ac333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letter_to_index(letter):\n",
    "    return ALL_LETTERS.find(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e08d2c1c-a613-4cfb-98c3-1a52865c22f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letter_to_tensor(letter):\n",
    "    tensor = torch.zeros(1, N_LETTERS)\n",
    "    tensor[0][letter_to_index(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8140a817-5b8d-483a-9bc3-29fc072979ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def line_to_tensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, N_LETTERS)\n",
    "    for i, letter in enumerate(line):\n",
    "        tensor[i][0][letter_to_index(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18487341-8313-419b-9ddd-73bfcb7a5c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_example(category_lines, all_categories):\n",
    "    \n",
    "    def random_choice(a):\n",
    "        random_idx = random.randint(0, len(a) - 1)\n",
    "        return a[random_idx]\n",
    "    \n",
    "    category = random_choice(all_categories)\n",
    "    line = random_choice(category_lines[category])\n",
    "    category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n",
    "    line_tensor = line_to_tensor(line)\n",
    "    return category, line, category_tensor, line_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fd2e603-3f3d-418e-9da4-031ba51852c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        # Fully connected layer for output\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input_tensor, hidden_state):\n",
    "        # LSTM expects input in the shape (batch, seq_len, input_size)\n",
    "        # Reshape input_tensor to include batch and seq_len if needed\n",
    "        input_tensor = input_tensor.unsqueeze(1)  # Adding seq_len=1 dimension\n",
    "        output, (hidden, cell) = self.lstm(input_tensor, hidden_state)\n",
    "        \n",
    "        # Pass the LSTM's hidden state through the output layer\n",
    "        output = self.fc(output.squeeze(1))  # Remove the seq_len dimension\n",
    "        return output, (hidden, cell)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Initialize both hidden and cell states as zeros\n",
    "        return (torch.zeros(1, 1, self.hidden_size),  # Hidden state\n",
    "                torch.zeros(1, 1, self.hidden_size))  # Cell state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcc605e6-6b74-46ae-a57d-de29c405aad3",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "category_lines, all_categories = load_data()\n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d9fc2e1-7e67-43ac-96b7-feb2af307cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_from_output(output):\n",
    "    category_idx = torch.argmax(output).item()\n",
    "    return all_categories[category_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6fdfd2b-7d12-4e74-8319-6d139d88c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "mdl  = LSTM(57, 100, 1)\n",
    "optimizer = torch.optim.Adam(mdl.parameters(), lr=learning_rate)\n",
    "\n",
    "def train(line_tensor, category_tensor):\n",
    "    hidden = mdl.init_hidden()\n",
    "    \n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = mdl(line_tensor[i], hidden)\n",
    "        \n",
    "    loss = criterion(output, category_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc648424-84f1-46f4-a274-eb5eb52a45f3",
   "metadata": {},
   "source": [
    "## Make it better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b6ed10d-49b3-4590-928b-790e1841681b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_lines_from_files(directory):\n",
    "    results = []  # To store the tuples\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.txt'):  # Process only .txt files\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                for line in file:\n",
    "                    line_content = line.strip()  # Remove leading/trailing whitespace\n",
    "                    results.append((line_content, filename.replace('.txt', '')))\n",
    "    return results\n",
    "\n",
    "directory_path = 'names'\n",
    "lines_with_files = read_lines_from_files(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "479a3950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lines_with_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8475d93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bff87f06-55a2-445c-acf0-30f22b398998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamesDataset:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, language = self.data[idx]\n",
    "        return name, language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7b71aca-abd9-469b-b337-93b13fdf22e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eef2550f-0eb9-499a-943d-66015cd14977",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = NamesDataset(lines_with_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ac1776b-5786-4389-85d7-0acb4cbb09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e26da7d-4993-459d-ad7a-34f24ef3c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = NamesDataset(lines_with_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f9faa5f-aa7b-466d-8192-795b6d9811db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input_tensor, hidden_state):\n",
    "        # LSTM expects input in the shape (batch, seq_len, input_size)\n",
    "        # Reshape input_tensor to include batch and seq_len if needed\n",
    "        input_tensor = input_tensor.unsqueeze(1)  # Adding seq_len=1 dimension\n",
    "        output, (hidden, cell) = self.lstm(input_tensor, hidden_state)\n",
    "        \n",
    "        # Pass the LSTM's hidden state through the output layer\n",
    "        output = self.fc(output.squeeze(1))  # Remove the seq_len dimension\n",
    "        return output, (hidden, cell)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Initialize both hidden and cell states as zeros\n",
    "        return (torch.zeros(1, 1, self.hidden_size),  # Hidden state\n",
    "                torch.zeros(1, 1, self.hidden_size))  # Cell state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "076f1bec-b5f3-454e-ba3d-26c2057b0610",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "mdl  = LSTM(57, 256, 18)\n",
    "optimizer = torch.optim.Adam(mdl.parameters(), lr=learning_rate)\n",
    "\n",
    "def train(line_tensor, category_tensor, hidden):\n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = mdl(line_tensor[i], hidden)\n",
    "    # set_trace()\n",
    "    loss = criterion(output, category_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b3017b7-612a-4521-86f9-25a2f9d9b0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name, guess and label Ugaki Russian Japanese\n",
      "WRONG\n",
      "name, guess and label Shichirobei Japanese Japanese\n",
      "CORRECT\n",
      "name, guess and label Sanchez English Spanish\n",
      "WRONG\n",
      "name, guess and label Garrett English English\n",
      "CORRECT\n",
      "name, guess and label Shalnov Russian Russian\n",
      "CORRECT\n",
      "name, guess and label Bazzi Japanese Arabic\n",
      "WRONG\n",
      "name, guess and label Vyucheisky Russian Russian\n",
      "CORRECT\n",
      "name, guess and label Gianakopulos Russian Greek\n",
      "WRONG\n",
      "name, guess and label Usynin Russian Russian\n",
      "CORRECT\n",
      "name, guess and label Chikhanchin Russian Russian\n",
      "CORRECT\n",
      "name, guess and label Inson English English\n",
      "CORRECT\n",
      "name, guess and label Damhan Russian Irish\n",
      "WRONG\n",
      "name, guess and label Marmazov Russian Russian\n",
      "CORRECT\n",
      "name, guess and label Elcock English English\n",
      "CORRECT\n",
      "name, guess and label Taidhg Russian Irish\n",
      "WRONG\n",
      "name, guess and label Bagretsoff Russian Russian\n",
      "CORRECT\n",
      "name, guess and label Rainbagin Russian Russian\n",
      "CORRECT\n",
      "name, guess and label Mawson English English\n",
      "CORRECT\n",
      "name, guess and label Kirkbright Russian English\n",
      "WRONG\n",
      "name, guess and label Downey English English\n",
      "CORRECT\n",
      "CPU times: user 1min 59s, sys: 7min 3s, total: 9min 3s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "exp = mlflow.set_experiment(experiment_name='lstm')\n",
    "\n",
    "with mlflow.start_run(experiment_id=exp.experiment_id, run_name='hidden_256'):\n",
    "    j = 0\n",
    "    accurate = 0\n",
    "    wrong = 0\n",
    "    current_loss = 0\n",
    "    all_losses = []\n",
    "    plot_steps, print_steps = 1000, 5000\n",
    "    num_epochs = 1\n",
    "    for i in range(num_epochs):\n",
    "        hidden = mdl.init_hidden()\n",
    "        for name, language in dl:\n",
    "            language = language[0]\n",
    "            name = name[0]\n",
    "            category_tensor = torch.tensor([all_categories.index(language)], dtype=torch.long)\n",
    "            line_tensor = line_to_tensor(name)\n",
    "            output, loss = train(line_tensor, category_tensor, hidden)\n",
    "            current_loss += loss \n",
    "\n",
    "            guess = category_from_output(output)\n",
    "            correct = \"CORRECT\" if guess == language else f\"WRONG ({language})\"\n",
    "            \n",
    "            if guess == language:\n",
    "                accurate +=1\n",
    "            else:\n",
    "                wrong +=1\n",
    "            \n",
    "            j+=1\n",
    "            if (j+1) % plot_steps == 0:\n",
    "                print('name, guess and label', name, guess, language)\n",
    "                if guess == language:\n",
    "                    print('CORRECT')\n",
    "                else:\n",
    "                    print('WRONG')\n",
    "                # print(f\"{i+1} {loss:.4f} {line} / {guess} {correct}\")\n",
    "    # mlflow.log_param('accuracy', accurate)\n",
    "    # mlflow.log_param('wrong', wrong)\n",
    "    accuracy = accurate / (accurate + wrong)\n",
    "    mlflow.log_param('accuracy', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c302a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6a3be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4494b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2118647b-4409-4484-ac9f-8030b721e0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15938, 4136)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accurate, wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a3f273e2-9735-4d39-9b5a-22af67875f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "24a72fb5-a428-4f5b-a11e-59bd37f5e86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chinese'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, _ = mdl(line_tensor[i], hidden)\n",
    "guess = category_from_output(output)\n",
    "guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "20c8ebef-bd7a-46a7-87ad-c65c058b7e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_line):\n",
    "    with torch.no_grad():\n",
    "        line_tensor = line_to_tensor(input_line)\n",
    "            \n",
    "        for i in range(line_tensor.size()[0]):\n",
    "            output, _ = mdl(line_tensor[i], hidden)\n",
    "            guess = category_from_output(output)\n",
    "            guess\n",
    "        \n",
    "        return guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c3713071-2b58-4d89-a488-c7322d82e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(input_line):\n",
    "#     with torch.no_grad():\n",
    "#         line_tensor = line_to_tensor(input_line)\n",
    "            \n",
    "#         for i in range(line_tensor.size()[0]):\n",
    "#             output, hidden = mdl(line_tensor[i], hidden)\n",
    "        \n",
    "#         guess = category_from_output(output)\n",
    "#         return guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52cfd7e7-ef6b-4d9e-87eb-11d16c0645a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\n",
    "    \"Ritchie\",\n",
    "    \"Rozinek\",\n",
    "    \"Ruba\",\n",
    "    \"Ruda\",\n",
    "    \"Rumisek\",\n",
    "    \"Ruzicka\",\n",
    "    \"Rypka\",\n",
    "    \"Rebka\",\n",
    "    \"Rzehak\",\n",
    "    \"Sabol\",\n",
    "    \"Safko\",\n",
    "    \"Samz\",\n",
    "    \"Sankovsky\",\n",
    "    \"Sappe\",\n",
    "    \"Sappe\",\n",
    "    \"Sarna\",\n",
    "    \"Satorie\",\n",
    "    \"Savchak\",\n",
    "    \"Svotak\",\n",
    "    \"Swatchak\",\n",
    "    \"Svocak\",\n",
    "    \"Svotchak\",\n",
    "    \"Schallom\",\n",
    "    \"Schenk\",\n",
    "    \"Schlantz\",\n",
    "    \"Schmeiser\",\n",
    "    \"Schneider\",\n",
    "    \"Schmied\",\n",
    "    \"Schubert\",\n",
    "    \"Schwarz\",\n",
    "    \"Schwartz\",\n",
    "    \"Sedmik\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6ca86353-d899-4822-853d-cb4e71153f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_names = [\n",
    "    \"Gaber\",\n",
    "    \"Haddad\",\n",
    "    \"Rahal\",\n",
    "    \"Koury\",\n",
    "    \"Harb\",\n",
    "    \"Mikhail\",\n",
    "    \"Dagher\",\n",
    "    \"Shadid\",\n",
    "    \"Boutros\",\n",
    "    \"Mikhail\",\n",
    "    \"Khouri\",\n",
    "    \"Nader\",\n",
    "    \"Issa\",\n",
    "    \"Harb\",\n",
    "    \"Dagher\",\n",
    "    \"Gerges\",\n",
    "    \"Morcos\",\n",
    "    \"Essa\",\n",
    "    \"Fakhoury\",\n",
    "    \"Tuma\",\n",
    "    \"Kattan\",\n",
    "    \"Totah\",\n",
    "    \"Qureshi\",\n",
    "    \"Nahas\",\n",
    "    \"Bitar\",\n",
    "    \"Tahan\",\n",
    "    \"Daher\",\n",
    "    \"Shammas\",\n",
    "    \"Kouri\",\n",
    "    \"Ganim\",\n",
    "    \"Daher\",\n",
    "    \"Awad\",\n",
    "    \"Malouf\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2da510ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_names = [\n",
    "    \"Yallop\",\n",
    "    \"Yang\",\n",
    "    \"Yapp\",\n",
    "    \"Yard\",\n",
    "    \"Yardley\",\n",
    "    \"Yarker\",\n",
    "    \"Yarlett\",\n",
    "    \"Yarnall\",\n",
    "    \"Yarnold\",\n",
    "    \"Yarwood\",\n",
    "    \"Yasmin\",\n",
    "    \"Yates\",\n",
    "    \"Yeadon\",\n",
    "    \"Yeardley\",\n",
    "    \"Yeardsley\",\n",
    "    \"Yeates\",\n",
    "    \"Yeatman\",\n",
    "    \"Yeldon\",\n",
    "    \"Yeoman\",\n",
    "    \"Yeomans\",\n",
    "    \"Yetman\",\n",
    "    \"Yeung\",\n",
    "    \"Yoman\",\n",
    "    \"Yomkins\",\n",
    "    \"York\",\n",
    "    \"Yorke\",\n",
    "    \"Yorston\",\n",
    "    \"Youlden\",\n",
    "    \"Young\",\n",
    "    \"Younge\",\n",
    "    \"Younis\",\n",
    "    \"Youssouf\",\n",
    "    \"Yule\",\n",
    "    \"Yusuf\",\n",
    "    \"Zaoui\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a25da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "russain_names = [\n",
    "    \"Umko\",\n",
    "    \"Tumolsky\",\n",
    "    \"Tumov\",\n",
    "    \"Tumunbayarov\",\n",
    "    \"Tundykov\",\n",
    "    \"Tuneev\",\n",
    "    \"Tunev\",\n",
    "    \"Tungusov\",\n",
    "    \"Tuniev\",\n",
    "    \"Tunik\",\n",
    "    \"Tunkin\",\n",
    "    \"Tunnikov\",\n",
    "    \"Tupalo\",\n",
    "    \"Tupihin\",\n",
    "    \"Tupikhin\",\n",
    "    \"Tupikin\",\n",
    "    \"Tupikov\",\n",
    "    \"Tupolev\",\n",
    "    \"Tuporshin\",\n",
    "    \"Tur\",\n",
    "    \"Turaev\",\n",
    "    \"Turanov\",\n",
    "    \"Turarov\",\n",
    "    \"Turashev\",\n",
    "    \"Turatbekov\",\n",
    "    \"Turbai\",\n",
    "    \"Turbanov\",\n",
    "    \"Turbin\",\n",
    "    \"Turchak\",\n",
    "    \"Turchaninov\",\n",
    "    \"Turchenko\",\n",
    "    \"Turchin\",\n",
    "    \"Turetskov\",\n",
    "    \"Turetsky\",\n",
    "    \"Turgenev\",\n",
    "    \"Turik\",\n",
    "    \"Turintsev\",\n",
    "    \"Turischev\",\n",
    "    \"Turiyansky\",\n",
    "    \"Turkestanov\",\n",
    "    \"Turkevich\",\n",
    "    \"Turkin\",\n",
    "    \"Turko\",\n",
    "    \"Turkov\",\n",
    "    \"Turkul\",\n",
    "    \"Turlak\",\n",
    "    \"Turlapov\",\n",
    "    \"Turlov\",\n",
    "    \"Turmanov\",\n",
    "    \"Turmilov\",\n",
    "    \"Turmov\",\n",
    "    \"Turno\",\n",
    "    \"Turov\",\n",
    "    \"Turoverov\",\n",
    "    \"Turovsky\",\n",
    "    \"Turovtsev\",\n",
    "    \"Turpaev\",\n",
    "    \"Turpyatko\",\n",
    "    \"Tursky\",\n",
    "    \"Tursunov\",\n",
    "    \"Turta\",\n",
    "    \"Turtsevich\",\n",
    "    \"Turtygin\",\n",
    "    \"Turubanov\",\n",
    "    \"Turuhin\",\n",
    "    \"Turukhin\",\n",
    "    \"Turulo\",\n",
    "    \"Turunov\",\n",
    "    \"Turupanov\",\n",
    "    \"Turushev\",\n",
    "    \"Turusin\",\n",
    "    \"Turusov\",\n",
    "    \"Turutin\",\n",
    "    \"Turyanov\",\n",
    "    \"Turyansky\",\n",
    "    \"Tuvin\",\n",
    "    \"Tuzin\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "730dcf93-bdbc-4e4d-a5ef-4989eb1d65ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5324675324675324"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = 0\n",
    "wrong = 0\n",
    "for name in russain_names:\n",
    "    res = predict(name)\n",
    "    if res == \"Russian\":\n",
    "        true +=1\n",
    "    else:\n",
    "        wrong +=1\n",
    "acc = true / (true + wrong)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b1c13410-7a36-4ef5-938a-01e12b29312a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('Wasem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a243d-a5ef-4fbd-8253-c53bc36a4caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while True:\n",
    "#     sentence = input(\"Input:\")\n",
    "#     if sentence == \"quit\":\n",
    "#         break\n",
    "    \n",
    "#     predict(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9491eefc-2189-4883-ad75-08db2f4f38df",
   "metadata": {},
   "source": [
    "Antonopoulos\n",
    "Antonopoulos\n",
    "Arvanitoyannis\n",
    "Avgerinos\n",
    "Banos\n",
    "Batsakis\n",
    "Bekyros\n",
    "Belesis\n",
    "Bertsimas\n",
    "Bilias\n",
    "Blades\n",
    "Bouloukos\n",
    "Brisimitzaki"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lstm_mlflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
