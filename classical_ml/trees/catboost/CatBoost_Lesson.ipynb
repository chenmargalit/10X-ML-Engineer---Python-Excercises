{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90d9030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you do not have the catboost package installed, please uncomment and run the following line\n",
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "822d8c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ed999c",
   "metadata": {},
   "source": [
    "# CatBoost: A Complete Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9956dd1",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "\n",
    "CatBoost is a high-performance open-source library for gradient boosting on decision trees developed by Yandex. \n",
    "It is particularly well-suited for classification, regression, and ranking tasks, and offers robust performance on categorical features without requiring one-hot encoding. \n",
    "In this lesson, we will cover:\n",
    "- What is CatBoost?\n",
    "- Key Features\n",
    "- Installation\n",
    "- Basic Implementation\n",
    "- Important Hyperparameters\n",
    "- Comparison with Other Gradient Boosting Algorithms\n",
    "- Tips and Tricks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8293f5ea",
   "metadata": {},
   "source": [
    "\n",
    "## What is CatBoost?\n",
    "\n",
    "CatBoost, short for \"Categorical Boosting,\" is an algorithm that efficiently handles categorical features without the need for extensive preprocessing like one-hot encoding or label encoding. \n",
    "It uses ordered boosting to prevent target leakage and performs well on imbalanced datasets. Its main advantages include:\n",
    "- **Handling Categorical Data:** Built-in support for categorical features, avoiding the curse of dimensionality associated with one-hot encoding.\n",
    "- **Efficient Training:** Fast training even on large datasets with high dimensions.\n",
    "- **Robust Performance:** Good out-of-the-box performance with minimal tuning.\n",
    "\n",
    "CatBoost is often compared with other boosting algorithms such as XGBoost and LightGBM, but its main edge comes from its categorical handling and lower susceptibility to overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb1313",
   "metadata": {},
   "source": [
    "\n",
    "## Key Features of CatBoost\n",
    "\n",
    "1. **Automatic Handling of Categorical Features:** CatBoost can work directly with categorical variables without the need for manual preprocessing.\n",
    "2. **Efficient Training:** The training process is fast due to efficient CPU and GPU implementations.\n",
    "3. **Ordered Boosting:** It uses ordered boosting to avoid target leakage during training.\n",
    "4. **Robust to Overfitting:** By using techniques such as feature combination and advanced regularization, CatBoost is less prone to overfitting than many other boosting algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d97479",
   "metadata": {},
   "source": [
    "\n",
    "## Important Hyperparameters\n",
    "\n",
    "Let's go through some of the most important hyperparameters of CatBoost:\n",
    "\n",
    "1. **iterations:** The maximum number of trees that can be built. A larger number of iterations can lead to better model performance but may increase training time and risk of overfitting.\n",
    "2. **depth:** The depth of the trees. A deeper tree can learn more complex patterns but may also lead to overfitting.\n",
    "3. **l2_leaf_reg:** L2 regularization coefficient. It helps in controlling overfitting by penalizing large weights.\n",
    "4. **border_count:** Number of splits for numerical features. Increasing `border_count` may improve model performance but can also increase training time.\n",
    "5. **eval_metric:** Metric used for evaluating model performance. Options include \"Accuracy,\" \"AUC,\" \"Logloss,\" etc.\n",
    "6. **cat_features:** List of categorical features (column indices) to be treated as categorical.\n",
    "7. **random_seed:** Seed for random number generation to ensure reproducibility.\n",
    "8. **verbose:** Verbosity of the training process (0 = silent, 1 = print updates)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f953930",
   "metadata": {},
   "source": [
    "### Optimizations sidenote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e93c1ee",
   "metadata": {},
   "source": [
    "Using astype('category') Pandas stores the name of the city as an int, not a string, and saves a lot of memeory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "074cdf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66.200132, 1.000635)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_size = 1_000_000\n",
    "data = pd.DataFrame({\n",
    "    'city': ['New York', 'Los Angeles', 'San Francisco', 'Chicago', 'Houston'] * (data_size // 5)\n",
    "})\n",
    "\n",
    "memory_usage_before = data.memory_usage(deep=True).sum() / 1_000_000\n",
    "\n",
    "data['city'] = data['city'].astype('category')\n",
    "\n",
    "memory_usage_after = data.memory_usage(deep=True).sum() / 1_000_000\n",
    "\n",
    "(memory_usage_before, memory_usage_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d27b9e3",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "For demonstration purposes, we will use the `iris` dataset. This is a classic classification dataset where the goal is to predict the species of iris based on its features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6d5a3bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "columns = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \n",
    "    \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \n",
    "    \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"\n",
    "]\n",
    "\n",
    "data = pd.read_csv(url, names=columns, na_values=\" ?\", sep=\",\\s*\", engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e61a8c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "afebf26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "income\n",
       "<=50K    24720\n",
       ">50K      7841\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['income'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8da08672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c004a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b0db2c72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['income'] = data['income'].apply(lambda x: 1 if x == \">50K\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bad5b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"income\", axis=1)\n",
    "y = data[\"income\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc6cc7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "for col in categorical_features:\n",
    "    X[col] = X[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "38f0ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e498484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_indices = [X_train.columns.get_loc(col) for col in categorical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77865c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8418689\ttotal: 23.8ms\tremaining: 11.9s\n",
      "50:\tlearn: 0.8812193\ttotal: 1.18s\tremaining: 10.4s\n",
      "100:\tlearn: 0.8931588\ttotal: 2.3s\tremaining: 9.07s\n",
      "150:\tlearn: 0.9073249\ttotal: 3.58s\tremaining: 8.27s\n",
      "200:\tlearn: 0.9159244\ttotal: 4.89s\tremaining: 7.27s\n",
      "250:\tlearn: 0.9237945\ttotal: 6.21s\tremaining: 6.16s\n",
      "300:\tlearn: 0.9322405\ttotal: 7.56s\tremaining: 5s\n",
      "350:\tlearn: 0.9390356\ttotal: 8.9s\tremaining: 3.78s\n",
      "400:\tlearn: 0.9446407\ttotal: 10.2s\tremaining: 2.53s\n",
      "450:\tlearn: 0.9495931\ttotal: 11.5s\tremaining: 1.25s\n",
      "499:\tlearn: 0.9532018\ttotal: 12.9s\tremaining: 0us\n",
      "CPU times: user 1min, sys: 9.47 s, total: 1min 9s\n",
      "Wall time: 13 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x174d5e390>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=500,             # Number of boosting iterations\n",
    "    learning_rate=0.1,          \n",
    "    depth=10,                   # Depth of the trees\n",
    "    l2_leaf_reg=3,              # L2 regularization\n",
    "    eval_metric='Accuracy',     # Evaluation metric\n",
    "    cat_features=cat_features_indices,  # Indices of categorical features\n",
    "    verbose=50,                 # Verbosity\n",
    "    random_seed=42              \n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d76db50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                          27\n",
       "workclass               Private\n",
       "fnlwgt                   160178\n",
       "education          Some-college\n",
       "education-num                10\n",
       "marital-status         Divorced\n",
       "occupation         Adm-clerical\n",
       "relationship      Not-in-family\n",
       "race                      White\n",
       "sex                      Female\n",
       "capital-gain                  0\n",
       "capital-loss                  0\n",
       "hours-per-week               38\n",
       "native-country    United-States\n",
       "Name: 14160, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "179a6b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "de305dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      4942\n",
      "           1       0.77      0.65      0.71      1571\n",
      "\n",
      "    accuracy                           0.87      6513\n",
      "   macro avg       0.83      0.80      0.81      6513\n",
      "weighted avg       0.87      0.87      0.87      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "af1ac357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Feature Id  Importances\n",
      "0              age    14.922751\n",
      "1       occupation    13.645859\n",
      "2           fnlwgt    10.743213\n",
      "3        education     8.548148\n",
      "4   hours-per-week     8.467470\n",
      "5     relationship     8.171926\n",
      "6   marital-status     7.753239\n",
      "7     capital-gain     6.999732\n",
      "8        workclass     6.457446\n",
      "9    education-num     3.559516\n",
      "10            race     3.156632\n",
      "11    capital-loss     3.018592\n",
      "12  native-country     2.342311\n",
      "13             sex     2.213165\n"
     ]
    }
   ],
   "source": [
    "importances = model.get_feature_importance(prettified=True)\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee561554",
   "metadata": {},
   "source": [
    "\n",
    "## Tips and Tricks\n",
    "\n",
    "1. **Hyperparameter Tuning:** Use grid search or random search to find the optimal set of hyperparameters for your specific dataset.\n",
    "2. **Categorical Features:** Always provide the `cat_features` parameter to leverage the strength of CatBoost's handling of categorical data.\n",
    "3. **GPU Training:** Use `task_type='GPU'` if you have a compatible GPU to speed up training on large datasets.\n",
    "4. **Handling Class Imbalance:** Use `class_weights` to handle imbalanced datasets.\n",
    "\n",
    "## Further Exploration\n",
    "\n",
    "To dive deeper into CatBoost, consider:\n",
    "- Exploring other evaluation metrics (`eval_metric`).\n",
    "- Experimenting with different boosting types (`boosting_type`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f1d1b0",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "CatBoost is a powerful and versatile gradient boosting algorithm that performs well on both numerical and categorical data. \n",
    "It is efficient, easy to use, and requires minimal preprocessing of categorical features. By leveraging its built-in functionalities and tuning its hyperparameters, you can achieve high performance on a wide range of machine learning tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all_purpose_venv",
   "language": "python",
   "name": "all_purpose_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
