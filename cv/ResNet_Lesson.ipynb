{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0895d669",
   "metadata": {},
   "source": [
    "# Residual Networks (ResNet)\n",
    "In this notebook, we explore ResNets, understand their architecture, and implement a ResNet-18 model using PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f38fe7",
   "metadata": {},
   "source": [
    "### **1. Why Residual Networks?**\n",
    "Deep networks often suffer from the vanishing gradient problem, making it difficult to train very deep architectures. ResNet introduces skip connections that allow gradients to flow directly through the network, enabling the training of networks with hundreds or even thousands of layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8405cb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Data Preparation\n",
    "def prepare_data(batch_size=64):\n",
    "    \"\"\"Prepares CIFAR-10 data for training and testing.\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = prepare_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3d7eb4",
   "metadata": {},
   "source": [
    "### **2. Understanding the ResNet Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e83943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def print_resnet_summary():\n",
    "    \"\"\"Prints the summary of ResNet-18.\"\"\"\n",
    "    model = resnet18(pretrained=False)  # Pretrained can be set to True for transfer learning\n",
    "    print(model)\n",
    "\n",
    "print_resnet_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab63ee1",
   "metadata": {},
   "source": [
    "### **3. Define Training and Evaluation Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "714974f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n",
    "    \"\"\"Train the ResNet model.\"\"\"\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs, labels\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"Evaluate the ResNet model.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs, labels\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef4c7a7",
   "metadata": {},
   "source": [
    "### **4. Instantiate and Train ResNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "063024ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1, Loss: 1.3707\n",
      "Accuracy: 61.49%\n",
      "CPU times: user 42min 14s, sys: 8min 52s, total: 51min 6s\n",
      "Wall time: 6min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Load the ResNet-18 model\n",
    "model = resnet18(pretrained=False, num_classes=10)\n",
    "# model = model.cuda()\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer, epochs=1)\n",
    "\n",
    "# Step 5: Evaluate the Model\n",
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc90e6d4",
   "metadata": {},
   "source": [
    "### **6. Visualizing Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319ba40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, test_loader):\n",
    "    \"\"\"Visualizes predictions on test images.\"\"\"\n",
    "    model.eval()\n",
    "    data_iter = iter(test_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    images, labels = images, labels\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "\n",
    "    # Unnormalize images for visualization\n",
    "    images = images.cpu().numpy().transpose((0, 2, 3, 1))\n",
    "    images = (images * 0.5) + 0.5\n",
    "\n",
    "    # Display the first 10 images and predictions\n",
    "    fig, axes = plt.subplots(1, 10, figsize=(15, 5))\n",
    "    for i in range(10):\n",
    "        axes[i].imshow(images[i])\n",
    "        axes[i].set_title(f\"Pred: {predictions[i].item()}\\nTrue: {labels[i].item()}\"\")\n",
    "        axes[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e64d87",
   "metadata": {},
   "source": [
    "### **Conclusion**\n",
    "In this notebook, we explored the ResNet architecture and trained a ResNet-18 model on the CIFAR-10 dataset. Residual connections help alleviate vanishing gradients and enable the training of very deep networks. Try experimenting with deeper versions like ResNet-50 or ResNet-101!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae51239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dba7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
