{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db17671a-603d-419a-99bb-053ee0cfda71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import io\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d4cc8cd-963d-4713-b9c9-6cad7172b83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_LETTERS = string.ascii_letters + \" .,;'\"\n",
    "N_LETTERS = len(ALL_LETTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c7ef11-6e9f-4c48-9857-8498057d5d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn' and c in ALL_LETTERS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b973c0f8-6423-4262-861a-7271ccfb3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = 'names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6432bae3-965d-48c6-a5fc-13fff6916839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(path):\n",
    "    return glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ec884b8-26f9-43c0-a612-d1b83038cc14",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T13:29:55.853104Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Build the category_lines dictionary, a list of names per language\n",
    "    category_lines = {}\n",
    "    all_categories = []\n",
    "    \n",
    "    # Read a file and split into lines\n",
    "    def read_lines(filename):\n",
    "        lines = io.open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "        return [unicode_to_ascii(line) for line in lines]\n",
    "    \n",
    "    for filename in find_files(f'{PATH_TO_DATA}/*.txt'):\n",
    "        category = os.path.splitext(os.path.basename(filename))[0]\n",
    "        all_categories.append(category)\n",
    "        \n",
    "        lines = read_lines(filename)\n",
    "        category_lines[category] = lines\n",
    "        \n",
    "    return category_lines, all_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ead7cda-da61-4f08-9a77-4fcc36c39fb6",
   "metadata": {},
   "source": [
    "To represent a single letter, we use a “one-hot vector” of size 1 x n_letters. A one-hot vector is filled with 0s except for a 1 at index of the current letter, e.g. \"b\" = <0 1 0 0 0 ...>.\n",
    "\n",
    "To make a word we join a bunch of those into a 2D matrix <line_length x 1 x n_letters>.\n",
    "\n",
    "That extra 1 dimension is because PyTorch assumes everything is in batches - we’re just using a batch size of 1 here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41523041-acd3-4457-a51f-42acb3efeaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_to_index(letter):\n",
    "    return ALL_LETTERS.find(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88086412-b462-457d-9921-0caface56485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_to_tensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, N_LETTERS)\n",
    "    for i, letter in enumerate(line):\n",
    "        tensor[i][0][letter_to_index(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5582358-22b1-4da9-9c10-8cd04f622be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_from_output(output):\n",
    "    category_idx = torch.argmax(output).item()\n",
    "    return all_categories[category_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4502f6d2-b938-4f1c-aa77-626502443faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_example(category_lines, all_categories):\n",
    "    \n",
    "    def random_choice(a):\n",
    "        random_idx = random.randint(0, len(a) - 1)\n",
    "        return a[random_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b6ed10d-49b3-4590-928b-790e1841681b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_lines_from_files(directory):\n",
    "    results = []  # To store the tuples\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.txt'):  # Process only .txt files\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                for line in file:\n",
    "                    line_content = line.strip()  # Remove leading/trailing whitespace\n",
    "                    results.append((line_content, filename.replace('.txt', '')))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e21821c2-80c2-40b7-8183-4ee6b586c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_lines, all_categories = load_data()\n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03cd41eb-2783-42d5-87ea-37d8c79f0392",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_with_files = read_lines_from_files(PATH_TO_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bff87f06-55a2-445c-acf0-30f22b398998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamesDataset:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, language = self.data[idx]\n",
    "        return name, language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eef2550f-0eb9-499a-943d-66015cd14977",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = NamesDataset(lines_with_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ac1776b-5786-4389-85d7-0acb4cbb09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1115e8ae-c9c8-4fa2-b95b-fd6c58f4568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input_tensor, hidden_state):\n",
    "        # LSTM expects input in the shape (batch, seq_len, input_size)\n",
    "        # Reshape input_tensor to include batch and seq_len\n",
    "        input_tensor = input_tensor.unsqueeze(1)\n",
    "        output, (hidden, cell) = self.lstm(input_tensor, hidden_state)\n",
    "        \n",
    "        # Pass the LSTM's hidden state through the output layer\n",
    "        output = self.fc(output.squeeze(1))  # Remove the seq_len dimension\n",
    "        return output, (hidden, cell)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        # Initialize both hidden and cell states as zeros\n",
    "        return (torch.zeros(1, 1, self.hidden_size),  # Hidden state\n",
    "                torch.zeros(1, 1, self.hidden_size))  # Cell state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d50d69f0-16fb-40b1-a928-8876cf746f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_helper(line_tensor, category_tensor, mdl):\n",
    "    hidden = mdl.init_hidden()\n",
    "    \n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = mdl(line_tensor[i], hidden)\n",
    "    loss = criterion(output, category_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f52ac372-7049-49a7-bc3d-d7f5bd81cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_letters = len(ALL_LETTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb081f7f-edd9-49a9-acad-acc15d92774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb02378d-3c74-4149-812b-22a46b7c4f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = LSTM(num_of_letters, 100, n_categories)\n",
    "optimizer = torch.optim.Adam(mdl.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2b536eb-e528-40ef-b691-5390d4392c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(mdl):\n",
    "    counter = 0\n",
    "    losses = []\n",
    "    num_correct = 0\n",
    "    num_wrong = 0\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        for name, language in dl:\n",
    "            language = language[0]\n",
    "            name = name[0]\n",
    "            category_tensor = torch.tensor([all_categories.index(language)], dtype=torch.long)\n",
    "            line_tensor = line_to_tensor(name)\n",
    "\n",
    "            output, loss = train_helper(line_tensor, category_tensor, mdl)\n",
    "            # current_loss += loss \n",
    "            counter +=1\n",
    "            if counter % 1000 == 0:\n",
    "                guess = category_from_output(output)\n",
    "                correct_or_wrong = f\"CORRECT {name, language}\" if guess == language else f\"WRONG ({language})\"\n",
    "                print(correct_or_wrong)\n",
    "                if guess == language:\n",
    "                    num_correct +=1\n",
    "                else:\n",
    "                    num_wrong+=1    \n",
    "        print('loss is', loss)\n",
    "    return num_correct, num_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51d24542-e3a6-4936-b84b-e77aab59fd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT ('Sordi', 'Italian')\n",
      "CORRECT ('Driml', 'Czech')\n",
      "CORRECT ('Miller', 'Scottish')\n",
      "CORRECT ('Lane', 'French')\n",
      "loss is 0.5893590450286865\n",
      "CORRECT ('Araullo', 'Spanish')\n",
      "CORRECT ('Addario', 'Italian')\n",
      "CORRECT ('Sonoda', 'Japanese')\n",
      "CORRECT ('Inao', 'Japanese')\n",
      "CORRECT ('Lavoie', 'French')\n",
      "loss is 0.052813444286584854\n",
      "CORRECT ('Caiazzo', 'Italian')\n",
      "CORRECT ('Ravenna', 'Italian')\n",
      "CORRECT ('Sorg', 'German')\n",
      "CORRECT ('Sauvageau', 'French')\n",
      "CORRECT ('Kriz', 'Czech')\n",
      "loss is 0.6205721497535706\n",
      "CORRECT ('Krakowski', 'Polish')\n",
      "CORRECT ('Sze', 'Chinese')\n",
      "CORRECT ('Márquez', 'Spanish')\n",
      "CORRECT ('Gass', 'German')\n",
      "CORRECT ('Klerken', 'Dutch')\n",
      "loss is 2.3007127310847864e-05\n",
      "CORRECT ('Okura', 'Japanese')\n",
      "CORRECT ('Necchi', 'Italian')\n",
      "CORRECT ('Huie', 'Chinese')\n",
      "CORRECT ('Schermer', 'German')\n",
      "CORRECT ('Brun', 'German')\n",
      "loss is 0.004707444459199905\n",
      "CORRECT ('Chevalier', 'French')\n",
      "CORRECT ('Torii', 'Japanese')\n",
      "CORRECT ('Fontaine', 'French')\n",
      "CORRECT ('Herrera', 'Spanish')\n",
      "CORRECT ('Lang', 'German')\n",
      "loss is 0.0028224652633070946\n",
      "CORRECT ('Mutsu', 'Japanese')\n",
      "CORRECT ('Terajima', 'Japanese')\n",
      "CORRECT ('Gallego', 'Spanish')\n",
      "CORRECT ('Hamaguchi', 'Japanese')\n",
      "CORRECT ('Ron', 'Korean')\n",
      "loss is 0.02445414289832115\n",
      "CORRECT ('Voigts', 'German')\n",
      "WRONG (Japanese)\n",
      "WRONG (Japanese)\n",
      "CORRECT ('Xian', 'Chinese')\n",
      "CORRECT ('Tosetti', 'Italian')\n",
      "loss is 0.31055375933647156\n",
      "WRONG (Spanish)\n",
      "CORRECT ('Szwedko', 'Polish')\n",
      "CORRECT ('Nervetti', 'Italian')\n",
      "CORRECT ('Komagata', 'Japanese')\n",
      "CORRECT ('Halle', 'German')\n",
      "loss is 0.0047418526373803616\n",
      "CORRECT ('Pesek', 'Czech')\n",
      "CORRECT ('Bischoffs', 'German')\n",
      "CORRECT ('Eng', 'Chinese')\n",
      "CORRECT ('Klimek', 'Polish')\n",
      "CORRECT ('Egonidis', 'Greek')\n",
      "loss is 7.152555099310121e-07\n",
      "CPU times: user 3min 6s, sys: 10min 42s, total: 13min 49s\n",
      "Wall time: 1min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9387755102040817"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "num_correct, num_wrong = train(mdl)\n",
    "num_correct / (num_correct + num_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3713071-2b58-4d89-a488-c7322d82e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_line, verbose=False):\n",
    "    with torch.no_grad():\n",
    "        line_tensor = line_to_tensor(input_line)\n",
    "        \n",
    "        hidden = mdl.init_hidden()\n",
    "    \n",
    "        for i in range(line_tensor.size()[0]):\n",
    "            output, hidden = mdl(line_tensor[i], hidden)\n",
    "        \n",
    "        guess = category_from_output(output)\n",
    "        if verbose is True:\n",
    "            print(guess)\n",
    "        return guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cba00282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polish\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Polish'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('Jaskulski', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc46f558-5155-4abe-8dd6-81ef3acc1a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_names = [\n",
    "    \"Khoury\", \"Nahas\", \"Daher\", \"Gerges\", \"Nazari\", \"Maalouf\", \"Gerges\", \"Naifeh\", \"Guirguis\", \n",
    "    \"Baba\", \"Sabbagh\", \"Attia\", \"Tahan\", \"Haddad\", \"Aswad\", \"Najjar\", \"Dagher\", \"Maloof\", \"Isa\", \n",
    "    \"Asghar\", \"Nader\", \"Gaber\", \"Abboud\", \"Maalouf\", \"Zogby\", \"Srour\", \"Bahar\", \"Mustafa\", \n",
    "    \"Hanania\", \"Daher\", \"Tuma\", \"Nahas\", \"Saliba\", \"Shamoon\", \"Handal\", \"Baba\", \"Amari\", \"Bahar\", \n",
    "    \"Atiyeh\", \"Said\", \"Khouri\", \"Tahan\", \"Baba\", \"Mustafa\", \"Guirguis\", \"Sleiman\", \"Seif\", \"Dagher\", \n",
    "    \"Bahar\", \"Gaber\", \"Harb\", \"Seif\", \"Asker\", \"Nader\", \"Antar\", \"Awad\", \"Srour\", \"Shadid\", \"Hajjar\", \n",
    "    \"Hanania\", \"Kalb\", \"Shadid\", \"Bazzi\", \"Mustafa\", \"Masih\", \"Ghanem\", \"Haddad\", \"Isa\", \"Antoun\", \n",
    "    \"Sarraf\", \"Sleiman\", \"Dagher\", \"Najjar\", \"Malouf\", \"Nahas\", \"Naser\", \"Saliba\", \"Shamon\", \"Malouf\", \n",
    "    \"Kalb\", \"Daher\", \"Maalouf\", \"Wasem\", \"Kanaan\", \"Naifeh\", \"Boutros\", \"Moghadam\", \"Masih\", \"Sleiman\", \n",
    "    \"Aswad\", \"Cham\", \"Assaf\", \"Quraishi\", \"Shalhoub\", \"Sabbag\", \"Mifsud\", \"Gaber\", \"Shammas\", \"Tannous\", \n",
    "    \"Sleiman\", \"Bazzi\", \"Quraishi\", \"Rahal\", \"Cham\", \"Ghanem\", \"Ghanem\", \"Naser\", \"Baba\", \"Shamon\", \n",
    "    \"Almasi\", \"Basara\", \"Quraishi\", \"Bata\", \"Wasem\", \"Shamoun\", \"Deeb\", \"Touma\", \"Asfour\", \"Deeb\", \n",
    "    \"Hadad\", \"Naifeh\", \"Touma\", \"Bazzi\", \"Shamoun\", \"Nahas\", \"Haddad\", \"Arian\", \"Kouri\", \"Deeb\", \n",
    "    \"Toma\", \"Halabi\", \"Nazari\", \"Saliba\", \"Fakhoury\", \"Hadad\", \"Baba\", \"Mansour\", \"Sayegh\", \"Antar\", \n",
    "    \"Deeb\", \"Morcos\", \"Shalhoub\", \"Sarraf\", \"Amari\", \"Wasem\", \"Ganim\", \"Tuma\", \"Fakhoury\", \"Hadad\", \n",
    "    \"Hakimi\", \"Nader\", \"Said\", \"Ganim\", \"Daher\", \"Ganem\", \"Tuma\", \"Boutros\", \"Aswad\", \"Sarkis\", \"Daher\", \n",
    "    \"Toma\", \"Boutros\", \"Kanaan\", \"Antar\", \"Gerges\", \"Kouri\", \"Maroun\", \"Wasem\", \"Dagher\", \"Naifeh\", \n",
    "    \"Bishara\", \"Ba\", \"Cham\", \"Kalb\", \"Bazzi\", \"Bitar\", \"Hadad\", \"Moghadam\", \"Sleiman\", \"Shamoun\", \n",
    "    \"Antar\", \"Atiyeh\", \"Koury\", \"Nahas\", \"Kouri\", \"Maroun\", \"Nassar\", \"Sayegh\", \"Haik\", \"Ghanem\", \n",
    "    \"Sayegh\", \"Salib\", \"Cham\", \"Bata\", \"Touma\", \"Antoun\", \"Antar\", \"Bata\", \"Botros\", \"Shammas\", \"Ganim\", \n",
    "    \"Sleiman\", \"Seif\", \"Moghadam\", \"Ba\", \"Tannous\", \"Bazzi\", \"Seif\", \"Salib\", \"Hadad\", \"Quraishi\", \n",
    "    \"Halabi\", \"Essa\", \"Bahar\", \"Kattan\", \"Boutros\", \"Nahas\", \"Sabbagh\", \"Kanaan\", \"Sayegh\", \"Said\", \n",
    "    \"Botros\", \"Najjar\", \"Toma\", \"Bata\", \"Atiyeh\", \"Halabi\", \"Tannous\", \"Kouri\", \"Shamoon\", \"Kassis\", \n",
    "    \"Haddad\", \"Tuma\", \"Mansour\", \"Antar\", \"Kassis\", \"Kalb\", \"Basara\", \"Rahal\", \"Mansour\", \"Handal\", \n",
    "    \"Morcos\", \"Fakhoury\", \"Hadad\", \"Morcos\", \"Kouri\", \"Quraishi\", \"Almasi\", \"Awad\", \"Naifeh\", \"Koury\", \n",
    "    \"Asker\", \"Maroun\", \"Fakhoury\", \"Sabbag\", \"Sarraf\", \"Shamon\", \"Assaf\", \"Boutros\", \"Malouf\", \"Nassar\", \n",
    "    \"Qureshi\", \"Ghanem\", \"Srour\", \"Almasi\", \"Qureshi\", \"Ghannam\", \"Mustafa\", \"Najjar\", \"Kassab\", \"Shadid\", \n",
    "    \"Shamoon\", \"Morcos\", \"Atiyeh\", \"Isa\", \"Ba\", \"Baz\", \"Asker\", \"Seif\", \"Asghar\", \"Hajjar\", \"Deeb\", \n",
    "    \"Essa\", \"Qureshi\", \"Abboud\", \"Ganem\", \"Haddad\", \"Koury\", \"Nassar\", \"Abadi\", \"Toma\", \"Tannous\", \n",
    "    \"Harb\", \"Issa\", \"Khouri\", \"Mifsud\", \"Kalb\", \"Gaber\", \"Ganim\", \"Boulos\", \"Samaha\", \"Haddad\", \n",
    "    \"Sabbag\", \"Wasem\", \"Dagher\", \"Rahal\", \"Atiyeh\", \"Antar\", \"Asghar\", \"Mansour\", \"Awad\", \"Boulos\", \n",
    "    \"Sarraf\", \"Deeb\", \"Abadi\", \"Nazari\", \"Daher\", \"Gerges\", \"Shamoon\", \"Gaber\", \"Amari\", \"Sarraf\", \n",
    "    \"Nazari\", \"Saliba\", \"Naifeh\", \"Nazari\", \"Hakimi\", \"Shamon\", \"Abboud\", \"Quraishi\", \"Tahan\", \"Safar\", \n",
    "    \"Hajjar\", \"Srour\", \"Gaber\", \"Shalhoub\", \"Attia\", \"Safar\", \"Said\", \"Ganem\", \"Nader\", \"Asghar\", \n",
    "    \"Mustafa\", \"Said\", \"Antar\", \"Botros\", \"Nader\", \"Ghannam\", \"Asfour\", \"Tahan\", \"Mansour\", \"Attia\", \n",
    "    \"Touma\", \"Najjar\", \"Kassis\", \"Abboud\", \"Bishara\", \"Bazzi\", \"Shalhoub\", \"Shalhoub\", \"Safar\", \"Khoury\", \n",
    "    \"Nazari\", \"Sabbag\", \"Sleiman\", \"Atiyeh\", \"Kouri\", \"Bitar\", \"Zogby\", \"Ghanem\", \"Assaf\", \"Abadi\", \n",
    "    \"Arian\", \"Shalhoub\", \"Khoury\", \"Morcos\", \"Shamon\", \"Wasem\", \"Abadi\", \"Antoun\", \"Baz\", \"Naser\", \n",
    "    \"Assaf\", \"Saliba\", \"Nader\", \"Mikhail\", \"Naser\", \"Daher\", \"Morcos\", \"Awad\", \"Nahas\", \"Sarkis\", \n",
    "    \"Malouf\", \"Mustafa\", \"Fakhoury\", \"Ghannam\", \"Shadid\", \"Gaber\", \"Koury\", \"Atiyeh\", \"Shamon\", \"Boutros\", \n",
    "    \"Sarraf\", \"Arian\", \"Fakhoury\", \"Abadi\", \"Kassab\", \"Nahas\", \"Quraishi\", \"Mansour\", \"Samaha\", \"Wasem\", \n",
    "    \"Seif\", \"Fakhoury\", \"Saliba\", \"Cham\", \"Bahar\", \"Shamoun\", \"Essa\", \"Shamon\", \"Asfour\", \"Bitar\", \n",
    "    \"Cham\", \"Tahan\", \"Tannous\", \"Daher\", \"Khoury\", \"Shamon\", \"Bahar\", \"Quraishi\", \"Ghannam\", \"Kassab\", \n",
    "    \"Zogby\", \"Basara\", \"Shammas\", \"Arian\", \"Sayegh\", \"Naifeh\", \"Mifsud\", \"Sleiman\", \"Arian\", \"Kassis\", \n",
    "    \"Shamoun\", \"Kassis\", \"Harb\", \"Mustafa\", \"Boulos\", \"Asghar\", \"Shamon\", \"Kanaan\", \"Atiyeh\", \"Kassab\", \n",
    "    \"Tahan\", \"Bazzi\", \"Kassis\", \"Qureshi\", \"Basara\", \"Shalhoub\", \"Sayegh\", \"Haik\", \"Attia\", \"Maroun\", \n",
    "    \"Kassis\", \"Sarkis\", \"Harb\", \"Assaf\", \"Kattan\", \"Antar\", \"Sleiman\", \"Touma\", \"Sarraf\", \"Bazzi\", \n",
    "    \"Boulos\", \"Baz\", \"Issa\", \"Shamon\", \"Shadid\", \"Deeb\", \"Sabbag\", \"Wasem\", \"Awad\", \"Mansour\", \"Saliba\", \n",
    "    \"Fakhoury\", \"Arian\", \"Bishara\", \"Dagher\", \"Bishara\", \"Koury\", \"Fakhoury\", \"Naser\", \"Nader\", \"Antar\", \n",
    "    \"Gerges\", \"Handal\", \"Hanania\", \"Shadid\", \"Gerges\", \"Kassis\", \"Essa\", \"Assaf\", \"Shadid\", \"Seif\", \n",
    "    \"Shalhoub\", \"Shamoun\", \"Hajjar\", \"Baba\", \"Sayegh\", \"Mustafa\", \"Sabbagh\", \"Isa\", \"Najjar\", \"Tannous\", \n",
    "    \"Hanania\", \"Ganem\", \"Gerges\", \"Fakhoury\", \"Mifsud\", \"Nahas\", \"Bishara\", \"Bishara\", \"Abadi\", \"Sarkis\", \n",
    "    \"Masih\", \"Isa\", \"Attia\", \"Kalb\", \"Essa\", \"Boulos\", \"Basara\", \"Halabi\", \"Halabi\", \"Dagher\", \"Attia\", \n",
    "    \"Kassis\", \"Tuma\", \"Gerges\", \"Ghannam\", \"Toma\", \"Baz\", \"Asghar\", \"Zogby\", \"Aswad\", \"Hadad\", \"Dagher\", \n",
    "    \"Naser\", \"Shadid\", \"Atiyeh\", \"Zogby\", \"Abboud\", \"Tannous\", \"Khouri\", \"Atiyeh\", \"Ganem\", \"Maalouf\", \n",
    "    \"Isa\", \"Maroun\", \"Issa\", \"Khouri\", \"Harb\", \"Nader\", \"Awad\", \"Nahas\", \"Said\", \"Baba\", \"Totah\", \"Ganim\", \n",
    "    \"Handal\", \"Mansour\", \"Basara\", \"Malouf\", \"Said\", \"Botros\", \"Samaha\", \"Safar\", \"Tahan\", \"Botros\", \n",
    "    \"Shamoun\", \"Handal\", \"Sarraf\", \"Malouf\", \"Bishara\", \"Aswad\", \"Khouri\", \"Baz\", \"Asker\", \"Toma\", \n",
    "    \"Koury\", \"Gerges\", \"Bishara\", \"Boulos\", \"Najjar\", \"Aswad\", \"Shamon\", \"Kouri\", \"Srour\", \"Assaf\", \n",
    "    \"Tannous\", \"Attia\", \"Mustafa\", \"Kattan\", \"Asghar\", \"Amari\", \"Shadid\", \"Said\", \"Bazzi\", \"Masih\", \n",
    "    \"Antar\", \"Fakhoury\", \"Shadid\", \"Masih\", \"Handal\", \"Sarraf\", \"Kassis\", \"Salib\", \"Hajjar\", \"Totah\", \n",
    "    \"Koury\", \"Totah\", \"Mustafa\", \"Sabbagh\", \"Moghadam\", \"Toma\", \"Srour\", \"Almasi\", \"Totah\", \"Maroun\", \n",
    "    \"Kattan\", \"Naifeh\", \"Sarkis\", \"Mikhail\", \"Nazari\", \"Boutros\", \"Guirguis\", \"Gaber\", \"Kassis\", \"Masih\", \n",
    "    \"Hanania\", \"Maloof\", \"Quraishi\", \"Cham\", \"Hadad\", \"Tahan\", \"Bitar\", \"Arian\", \"Gaber\", \"Baz\", \n",
    "    \"Mansour\", \"Kalb\", \"Sarkis\", \"Attia\", \"Antar\", \"Asfour\", \"Said\", \"Essa\", \"Koury\", \"Hadad\", \"Tuma\", \n",
    "    \"Moghadam\", \"Sabbagh\", \"Amari\", \"Dagher\", \"Srour\", \"Antoun\", \"Sleiman\", \"Maroun\", \"Tuma\", \"Nahas\", \n",
    "    \"Hanania\", \"Sayegh\", \"Amari\", \"Sabbagh\", \"Said\", \"Cham\", \"Asker\", \"Nassar\", \"Bitar\", \"Said\", \"Dagher\", \n",
    "    \"Safar\", \"Khouri\", \"Totah\", \"Khoury\", \"Salib\", \"Basara\", \"Abboud\", \"Baz\", \"Isa\", \"Cham\", \"Amari\", \n",
    "    \"Mifsud\", \"Hadad\", \"Rahal\", \"Khoury\", \"Bazzi\", \"Basara\", \"Totah\", \"Ghannam\", \"Koury\", \"Malouf\", \n",
    "    \"Zogby\", \"Zogby\", \"Boutros\", \"Nassar\", \"Handal\", \"Hajjar\", \"Maloof\", \"Abadi\", \"Maroun\", \"Mifsud\", \n",
    "    \"Kalb\", \"Amari\", \"Hakimi\", \"Boutros\", \"Masih\", \"Kattan\", \"Haddad\", \"Arian\", \"Nazari\", \"Assaf\", \n",
    "    \"Attia\", \"Wasem\", \"Gerges\", \"Asker\", \"Tahan\", \"Fakhoury\", \"Shadid\", \"Sarraf\", \"Attia\", \"Naifeh\", \n",
    "    \"Aswad\", \"Deeb\", \"Tannous\", \"Totah\", \"Cham\", \"Baba\", \"Najjar\", \"Hajjar\", \"Shamoon\", \"Handal\", \n",
    "    \"Awad\", \"Guirguis\", \"Awad\", \"Ganem\", \"Naifeh\", \"Khoury\", \"Hajjar\", \"Moghadam\", \"Mikhail\", \"Ghannam\", \n",
    "    \"Guirguis\", \"Tannous\", \"Kanaan\", \"Handal\", \"Khoury\", \"Kalb\", \"Qureshi\", \"Najjar\", \"Atiyeh\", \"Gerges\", \n",
    "    \"Nassar\", \"Tahan\", \"Hadad\", \"Fakhoury\", \"Salib\", \"Wasem\", \"Bitar\", \"Fakhoury\", \"Attia\", \"Awad\", \n",
    "    \"Totah\", \"Deeb\", \"Touma\", \"Botros\", \"Nazari\", \"Nahas\", \"Kouri\", \"Ghannam\", \"Assaf\", \"Asfour\", \n",
    "    \"Sarraf\", \"Naifeh\", \"Toma\", \"Asghar\", \"Abboud\", \"Issa\", \"Sabbag\", \"Sabbagh\", \"Isa\", \"Koury\", \n",
    "    \"Kattan\", \"Shamoon\", \"Rahal\", \"Kalb\", \"Naser\", \"Masih\", \"Sayegh\", \"Dagher\", \"Asker\", \"Maroun\", \n",
    "    \"Dagher\", \"Sleiman\", \"Botros\", \"Sleiman\", \"Harb\", \"Tahan\", \"Tuma\", \"Said\", \"Hadad\", \"Samaha\", \n",
    "    \"Harb\", \"Cham\", \"Atiyeh\", \"Haik\", \"Malouf\", \"Bazzi\", \"Harb\", \"Malouf\", \"Ghanem\", \"Cham\", \"Asghar\", \n",
    "    \"Samaha\", \"Khouri\", \"Nassar\", \"Rahal\", \"Baz\", \"Kalb\", \"Rahal\", \"Gerges\", \"Cham\", \"Sayegh\", \n",
    "    \"Shadid\", \"Morcos\", \"Shamoon\", \"Hakimi\", \"Shamoon\", \"Qureshi\", \"Ganim\", \"Shadid\", \"Khoury\", \n",
    "    \"Boutros\", \"Hanania\", \"Antoun\", \"Naifeh\", \"Deeb\", \"Samaha\", \"Awad\", \"Asghar\", \"Awad\", \"Saliba\", \n",
    "    \"Shamoun\", \"Mikhail\", \"Hakimi\", \"Mikhail\", \"Cham\", \"Halabi\", \"Sarkis\", \"Kattan\", \"Nazari\", \n",
    "    \"Safar\", \"Morcos\", \"Khoury\", \"Essa\", \"Nassar\", \"Haik\", \"Shadid\", \"Fakhoury\", \"Najjar\", \"Arian\", \n",
    "    \"Botros\", \"Daher\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3137854b-076e-47a7-aa89-d880b7a8ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_names = [\n",
    "    \"Abel\", \"Abraham\", \"Adam\", \"Albert\", \"Allard\", \"Archambault\", \"Armistead\", \"Arthur\", \"Augustin\", \n",
    "    \"Babineaux\", \"Baudin\", \"Beauchene\", \"Beaulieu\", \"Beaumont\", \"Bélanger\", \"Bellamy\", \"Bellerose\", \n",
    "    \"Belrose\", \"Berger\", \"Béringer\", \"Bernard\", \"Bertrand\", \"Bisset\", \"Bissette\", \"Blaise\", \"Blanc\", \n",
    "    \"Blanchet\", \"Blanchett\", \"Bonfils\", \"Bonheur\", \"Bonhomme\", \"Bonnaire\", \"Bonnay\", \"Bonner\", \n",
    "    \"Bonnet\", \"Borde\", \"Bordelon\", \"Bouchard\", \"Boucher\", \"Brisbois\", \"Brodeur\", \"Bureau\", \"Caron\", \n",
    "    \"Cavey\", \"Chaput\", \"Charbonneau\", \"Charpentier\", \"Charron\", \"Chastain\", \"Chevalier\", \"Chevrolet\", \n",
    "    \"Cloutier\", \"Colbert\", \"Comtois\", \"Cornett\", \"Coté\", \"Coupe\", \"Courtemanche\", \"Cousineau\", \n",
    "    \"Couture\", \"Daniau\", \"D'aramitz\", \"Daviau\", \"David\", \"Deforest\", \"Degarmo\", \"Delacroix\", \n",
    "    \"De la fontaine\", \"Deniau\", \"Deniaud\", \"Deniel\", \"Denis\", \"De sauveterre\", \"Deschamps\", \n",
    "    \"Descoteaux\", \"Desjardins\", \"Desrochers\", \"Desrosiers\", \"Dubois\", \"Duchamps\", \"Dufort\", \"Dufour\", \n",
    "    \"Duguay\", \"Dupond\", \"Dupont\", \"Durand\", \"Durant\", \"Duval\", \"Émile\", \"Eustis\", \"Fabian\", \"Fabre\", \n",
    "    \"Fabron\", \"Faucher\", \"Faucheux\", \"Faure\", \"Favager\", \"Favre\", \"Favreau\", \"Fay\", \"Félix\", \"Firmin\", \n",
    "    \"Fontaine\", \"Forest\", \"Forestier\", \"Fortier\", \"Foss\", \"Fournier\", \"Gage\", \"Gagne\", \"Gagnier\", \n",
    "    \"Gagnon\", \"Garcon\", \"Gardinier\", \"Germain\", \"Géroux\", \"Giles\", \"Girard\", \"Giroux\", \"Glaisyer\", \n",
    "    \"Gosse\", \"Gosselin\", \"Granger\", \"Guérin\", \"Guillory\", \"Hardy\", \"Harman\", \"Hébert\", \"Herbert\", \n",
    "    \"Herriot\", \"Jacques\", \"Janvier\", \"Jordan\", \"Joubert\", \"Labelle\", \"Lachance\", \"Lachapelle\", \n",
    "    \"Lamar\", \"Lambert\", \"Lane\", \"Langlais\", \"Langlois\", \"Lapointe\", \"Larue\", \"Laurent\", \"Lavigne\", \n",
    "    \"Lavoie\", \"Leandres\", \"Lebeau\", \"Leblanc\", \"Leclair\", \"Leclerc\", \"Lécuyer\", \"Lefebvre\", \n",
    "    \"Lefévre\", \"Lefurgey\", \"Legrand\", \"Lemaire\", \"Lémieux\", \"Leon\", \"Leroy\", \"Lesauvage\", \n",
    "    \"Lestrange\", \"Lévêque\", \"Lévesque\", \"Linville\", \"Lyon\", \"Lyon\", \"Maçon\", \"Marchand\", \"Marie\", \n",
    "    \"Marion\", \"Martel\", \"Martel\", \"Martin\", \"Masson\", \"Masson\", \"Mathieu\", \"Mercier\", \"Merle\", \n",
    "    \"Michaud\", \"Michel\", \"Monet\", \"Monette\", \"Montagne\", \"Moreau\", \"Moulin\", \"Mullins\", \"Noel\", \n",
    "    \"Oliver\", \"Olivier\", \"Page\", \"Paget\", \"Palomer\", \"Pan\", \"Pape\", \"Paquet\", \"Paquet\", \"Parent\", \n",
    "    \"Paris\", \"Parris\", \"Pascal\", \"Patenaude\", \"Paternoster\", \"Paul\", \"Pelletier\", \"Perrault\", \n",
    "    \"Perreault\", \"Perrot\", \"Petit\", \"Pettigrew\", \"Pierre\", \"Plamondon\", \"Plourde\", \"Poingdestre\", \n",
    "    \"Poirier\", \"Porcher\", \"Poulin\", \"Proulx\", \"Renaud\", \"Rey\", \"Reyer\", \"Richard\", \"Richelieu\", \n",
    "    \"Robert\", \"Roche\", \"Rome\", \"Romilly\", \"Rose\", \"Rousseau\", \"Roux\", \"Roy\", \"Royer\", \"Salomon\", \n",
    "    \"Salvage\", \"Samson\", \"Samuel\", \"Sargent\", \"Sarkozi\", \"Sarkozy\", \"Sartre\", \"Sault\", \"Sauvage\", \n",
    "    \"Sauvageau\", \"Sauvageon\", \"Sauvageot\", \"Sauveterre\", \"Savatier\", \"Segal\", \"Sergeant\", \n",
    "    \"Séverin\", \"Simon\", \"Solomon\", \"Soucy\", \"St martin\", \"St pierre\", \"Tailler\", \"Tasse\", \n",
    "    \"Thayer\", \"Thibault\", \"Thomas\", \"Tobias\", \"Tolbert\", \"Traver\", \"Travere\", \"Travers\", \"Traverse\", \n",
    "    \"Travert\", \"Tremblay\", \"Tremble\", \"Victor\", \"Victors\", \"Villeneuve\", \"Vincent\", \"Vipond\", \n",
    "    \"Voclain\", \"Yount\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fcec9bd1-b589-477e-b968-378ccdd2f389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "true = 0\n",
    "wrong = 0\n",
    "for name in arabic_names:\n",
    "    res = predict(name)\n",
    "    if res == 'Arabic':\n",
    "        true +=1\n",
    "    else:\n",
    "        wrong +=1\n",
    "        \n",
    "print((true / (true+wrong)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de7a7d2c-f7f1-4d7e-8ddf-55b36519fa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927797833935018\n"
     ]
    }
   ],
   "source": [
    "true = 0\n",
    "wrong = 0\n",
    "for name in french_names:\n",
    "    res = predict(name)\n",
    "    if res == 'French':\n",
    "        true +=1\n",
    "    else:\n",
    "        wrong +=1\n",
    "        \n",
    "print((true / (true+wrong)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e5395-560f-4845-ae9d-a648c2b14b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all_purpose_venv",
   "language": "python",
   "name": "all_purpose_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
