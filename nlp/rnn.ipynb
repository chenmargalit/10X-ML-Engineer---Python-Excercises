{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "db17671a-603d-419a-99bb-053ee0cfda71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import io\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6d4cc8cd-963d-4713-b9c9-6cad7172b83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_LETTERS = string.ascii_letters + \" .,;'\"\n",
    "N_LETTERS = len(ALL_LETTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "062805bb-65f7-4743-a9a3-8fe9033bc70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'\""
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALL_LETTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "02c7ef11-6e9f-4c48-9857-8498057d5d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn' and c in ALL_LETTERS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b973c0f8-6423-4262-861a-7271ccfb3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '../names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6432bae3-965d-48c6-a5fc-13fff6916839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(path):\n",
    "    return glob.glob(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5ec884b8-26f9-43c0-a612-d1b83038cc14",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-01T13:29:55.853104Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Build the category_lines dictionary, a list of names per language\n",
    "    category_lines = {}\n",
    "    all_categories = []\n",
    "    \n",
    "    # Read a file and split into lines\n",
    "    def read_lines(filename):\n",
    "        lines = io.open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "        return [unicode_to_ascii(line) for line in lines]\n",
    "    \n",
    "    for filename in find_files(f'{PATH_TO_DATA}/*.txt'):\n",
    "        category = os.path.splitext(os.path.basename(filename))[0]\n",
    "        all_categories.append(category)\n",
    "        \n",
    "        lines = read_lines(filename)\n",
    "        category_lines[category] = lines\n",
    "        \n",
    "    return category_lines, all_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ead7cda-da61-4f08-9a77-4fcc36c39fb6",
   "metadata": {},
   "source": [
    "To represent a single letter, we use a “one-hot vector” of size 1 x n_letters. A one-hot vector is filled with 0s except for a 1 at index of the current letter, e.g. \"b\" = <0 1 0 0 0 ...>.\n",
    "\n",
    "To make a word we join a bunch of those into a 2D matrix <line_length x 1 x n_letters>.\n",
    "\n",
    "That extra 1 dimension is because PyTorch assumes everything is in batches - we’re just using a batch size of 1 here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "41523041-acd3-4457-a51f-42acb3efeaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_to_index(letter):\n",
    "    return ALL_LETTERS.find(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "88086412-b462-457d-9921-0caface56485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_to_tensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, N_LETTERS)\n",
    "    for i, letter in enumerate(line):\n",
    "        tensor[i][0][letter_to_index(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f5582358-22b1-4da9-9c10-8cd04f622be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_from_output(output):\n",
    "    category_idx = torch.argmax(output).item()\n",
    "    return all_categories[category_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4502f6d2-b938-4f1c-aa77-626502443faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_training_example(category_lines, all_categories):\n",
    "    \n",
    "    def random_choice(a):\n",
    "        random_idx = random.randint(0, len(a) - 1)\n",
    "        return a[random_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8b6ed10d-49b3-4590-928b-790e1841681b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_lines_from_files(directory):\n",
    "    results = []  # To store the tuples\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.txt'):  # Process only .txt files\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                for line in file:\n",
    "                    line_content = line.strip()  # Remove leading/trailing whitespace\n",
    "                    results.append((line_content, filename.replace('.txt', '')))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e21821c2-80c2-40b7-8183-4ee6b586c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_lines, all_categories = load_data()\n",
    "n_categories = len(all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4e845f75-9a0d-45a5-9a61-88cd9fa9c6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "03cd41eb-2783-42d5-87ea-37d8c79f0392",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_with_files = read_lines_from_files(PATH_TO_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6f801c90-01d4-4294-ac2a-77f22e52794b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Abl', 'Czech'),\n",
       " ('Adsit', 'Czech'),\n",
       " ('Ajdrna', 'Czech'),\n",
       " ('Alt', 'Czech'),\n",
       " ('Antonowitsch', 'Czech')]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_with_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bff87f06-55a2-445c-acf0-30f22b398998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamesDataset:\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, language = self.data[idx]\n",
    "        return name, language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "eef2550f-0eb9-499a-943d-66015cd14977",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = NamesDataset(lines_with_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4ac1776b-5786-4389-85d7-0acb4cbb09b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1115e8ae-c9c8-4fa2-b95b-fd6c58f4568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input_tensor, hidden_tensor):\n",
    "        combined = torch.cat((input_tensor, hidden_tensor), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d50d69f0-16fb-40b1-a928-8876cf746f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_helper(line_tensor, category_tensor):\n",
    "    hidden = rnn.init_hidden()\n",
    "    \n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "    loss = criterion(output, category_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "43080eba-b20d-45d5-9bf3-249f5dd508cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 128\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2eea40c5-8853-45a6-a6a9-67199513cb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_LETTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fb081f7f-edd9-49a9-acad-acc15d92774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(N_LETTERS, n_hidden, n_categories)\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d2b536eb-e528-40ef-b691-5390d4392c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    counter = 0\n",
    "    losses = []\n",
    "    num_correct = 0\n",
    "    num_wrong = 0\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        for name, language in dl:\n",
    "            language = language[0]\n",
    "            name = name[0]\n",
    "            category_tensor = torch.tensor([all_categories.index(language)], dtype=torch.long)\n",
    "            line_tensor = line_to_tensor(name)\n",
    "\n",
    "            output, loss = train_helper(line_tensor, category_tensor)\n",
    "            # current_loss += loss \n",
    "            counter +=1\n",
    "            if counter % 1000 == 0:\n",
    "                guess = category_from_output(output)\n",
    "                correct_or_wrong = f\"CORRECT {name, language}\" if guess == language else f\"WRONG ({language})\"\n",
    "                print(correct_or_wrong)\n",
    "                if guess == language:\n",
    "                    num_correct +=1\n",
    "                else:\n",
    "                    num_wrong+=1    \n",
    "        print('loss is', loss)\n",
    "    return num_correct, num_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "51d24542-e3a6-4936-b84b-e77aab59fd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT ('Mccann', 'English')\n",
      "CORRECT ('Moldovanov', 'Russian')\n",
      "CORRECT ('Tuikin', 'Russian')\n",
      "CORRECT ('Avdeichikov', 'Russian')\n",
      "CORRECT ('Ivchenko', 'Russian')\n",
      "CORRECT ('Moshnyakov', 'Russian')\n",
      "CORRECT ('Fogg', 'English')\n",
      "CORRECT ('Admakin', 'Russian')\n",
      "CORRECT ('Handley', 'English')\n",
      "WRONG (English)\n",
      "CORRECT (\"Tzel'Ko\", 'Russian')\n",
      "CORRECT ('Leeming', 'English')\n",
      "CORRECT ('Kellems', 'English')\n",
      "WRONG (English)\n",
      "CORRECT ('Markholenko', 'Russian')\n",
      "CORRECT ('Homsky', 'Russian')\n",
      "CORRECT ('Prigozhy', 'Russian')\n",
      "WRONG (Russian)\n",
      "CORRECT ('Albitsky', 'Russian')\n",
      "WRONG (Czech)\n",
      "loss is 0.023027274757623672\n",
      "CORRECT ('Mozhaikin', 'Russian')\n",
      "CORRECT ('Illingworth', 'English')\n",
      "CORRECT ('Jukovsky', 'Russian')\n",
      "CORRECT ('Dubin', 'Russian')\n",
      "WRONG (German)\n",
      "CORRECT ('Dzhanaev', 'Russian')\n",
      "CORRECT ('Haidukov', 'Russian')\n",
      "WRONG (English)\n",
      "WRONG (Arabic)\n",
      "CORRECT ('Longo', 'Italian')\n",
      "WRONG (Portuguese)\n",
      "WRONG (Arabic)\n",
      "WRONG (Chinese)\n",
      "CORRECT ('Close', 'English')\n",
      "WRONG (Russian)\n",
      "CORRECT ('Ghanem', 'Arabic')\n",
      "WRONG (English)\n",
      "CORRECT ('Valtchuk', 'Russian')\n",
      "CORRECT ('Zhogin', 'Russian')\n",
      "WRONG (Russian)\n",
      "loss is 0.014346901327371597\n"
     ]
    }
   ],
   "source": [
    "num_correct, num_wrong = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4b4c1c00-7fd7-4671-8c6e-bb2e9e85cd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.675"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_correct / (num_correct + num_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c3713071-2b58-4d89-a488-c7322d82e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_line, verbose=False):\n",
    "    with torch.no_grad():\n",
    "        line_tensor = line_to_tensor(input_line)\n",
    "        \n",
    "        hidden = rnn.init_hidden()\n",
    "    \n",
    "        for i in range(line_tensor.size()[0]):\n",
    "            output, hidden = rnn(line_tensor[i], hidden)\n",
    "        \n",
    "        guess = category_from_output(output)\n",
    "        if verbose is True:\n",
    "            print(guess)\n",
    "        return guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cba00282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Russian\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Russian'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict('Jaskulski', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc46f558-5155-4abe-8dd6-81ef3acc1a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_names = [\n",
    "    \"Khoury\", \"Nahas\", \"Daher\", \"Gerges\", \"Nazari\", \"Maalouf\", \"Gerges\", \"Naifeh\", \"Guirguis\", \n",
    "    \"Baba\", \"Sabbagh\", \"Attia\", \"Tahan\", \"Haddad\", \"Aswad\", \"Najjar\", \"Dagher\", \"Maloof\", \"Isa\", \n",
    "    \"Asghar\", \"Nader\", \"Gaber\", \"Abboud\", \"Maalouf\", \"Zogby\", \"Srour\", \"Bahar\", \"Mustafa\", \n",
    "    \"Hanania\", \"Daher\", \"Tuma\", \"Nahas\", \"Saliba\", \"Shamoon\", \"Handal\", \"Baba\", \"Amari\", \"Bahar\", \n",
    "    \"Atiyeh\", \"Said\", \"Khouri\", \"Tahan\", \"Baba\", \"Mustafa\", \"Guirguis\", \"Sleiman\", \"Seif\", \"Dagher\", \n",
    "    \"Bahar\", \"Gaber\", \"Harb\", \"Seif\", \"Asker\", \"Nader\", \"Antar\", \"Awad\", \"Srour\", \"Shadid\", \"Hajjar\", \n",
    "    \"Hanania\", \"Kalb\", \"Shadid\", \"Bazzi\", \"Mustafa\", \"Masih\", \"Ghanem\", \"Haddad\", \"Isa\", \"Antoun\", \n",
    "    \"Sarraf\", \"Sleiman\", \"Dagher\", \"Najjar\", \"Malouf\", \"Nahas\", \"Naser\", \"Saliba\", \"Shamon\", \"Malouf\", \n",
    "    \"Kalb\", \"Daher\", \"Maalouf\", \"Wasem\", \"Kanaan\", \"Naifeh\", \"Boutros\", \"Moghadam\", \"Masih\", \"Sleiman\", \n",
    "    \"Aswad\", \"Cham\", \"Assaf\", \"Quraishi\", \"Shalhoub\", \"Sabbag\", \"Mifsud\", \"Gaber\", \"Shammas\", \"Tannous\", \n",
    "    \"Sleiman\", \"Bazzi\", \"Quraishi\", \"Rahal\", \"Cham\", \"Ghanem\", \"Ghanem\", \"Naser\", \"Baba\", \"Shamon\", \n",
    "    \"Almasi\", \"Basara\", \"Quraishi\", \"Bata\", \"Wasem\", \"Shamoun\", \"Deeb\", \"Touma\", \"Asfour\", \"Deeb\", \n",
    "    \"Hadad\", \"Naifeh\", \"Touma\", \"Bazzi\", \"Shamoun\", \"Nahas\", \"Haddad\", \"Arian\", \"Kouri\", \"Deeb\", \n",
    "    \"Toma\", \"Halabi\", \"Nazari\", \"Saliba\", \"Fakhoury\", \"Hadad\", \"Baba\", \"Mansour\", \"Sayegh\", \"Antar\", \n",
    "    \"Deeb\", \"Morcos\", \"Shalhoub\", \"Sarraf\", \"Amari\", \"Wasem\", \"Ganim\", \"Tuma\", \"Fakhoury\", \"Hadad\", \n",
    "    \"Hakimi\", \"Nader\", \"Said\", \"Ganim\", \"Daher\", \"Ganem\", \"Tuma\", \"Boutros\", \"Aswad\", \"Sarkis\", \"Daher\", \n",
    "    \"Toma\", \"Boutros\", \"Kanaan\", \"Antar\", \"Gerges\", \"Kouri\", \"Maroun\", \"Wasem\", \"Dagher\", \"Naifeh\", \n",
    "    \"Bishara\", \"Ba\", \"Cham\", \"Kalb\", \"Bazzi\", \"Bitar\", \"Hadad\", \"Moghadam\", \"Sleiman\", \"Shamoun\", \n",
    "    \"Antar\", \"Atiyeh\", \"Koury\", \"Nahas\", \"Kouri\", \"Maroun\", \"Nassar\", \"Sayegh\", \"Haik\", \"Ghanem\", \n",
    "    \"Sayegh\", \"Salib\", \"Cham\", \"Bata\", \"Touma\", \"Antoun\", \"Antar\", \"Bata\", \"Botros\", \"Shammas\", \"Ganim\", \n",
    "    \"Sleiman\", \"Seif\", \"Moghadam\", \"Ba\", \"Tannous\", \"Bazzi\", \"Seif\", \"Salib\", \"Hadad\", \"Quraishi\", \n",
    "    \"Halabi\", \"Essa\", \"Bahar\", \"Kattan\", \"Boutros\", \"Nahas\", \"Sabbagh\", \"Kanaan\", \"Sayegh\", \"Said\", \n",
    "    \"Botros\", \"Najjar\", \"Toma\", \"Bata\", \"Atiyeh\", \"Halabi\", \"Tannous\", \"Kouri\", \"Shamoon\", \"Kassis\", \n",
    "    \"Haddad\", \"Tuma\", \"Mansour\", \"Antar\", \"Kassis\", \"Kalb\", \"Basara\", \"Rahal\", \"Mansour\", \"Handal\", \n",
    "    \"Morcos\", \"Fakhoury\", \"Hadad\", \"Morcos\", \"Kouri\", \"Quraishi\", \"Almasi\", \"Awad\", \"Naifeh\", \"Koury\", \n",
    "    \"Asker\", \"Maroun\", \"Fakhoury\", \"Sabbag\", \"Sarraf\", \"Shamon\", \"Assaf\", \"Boutros\", \"Malouf\", \"Nassar\", \n",
    "    \"Qureshi\", \"Ghanem\", \"Srour\", \"Almasi\", \"Qureshi\", \"Ghannam\", \"Mustafa\", \"Najjar\", \"Kassab\", \"Shadid\", \n",
    "    \"Shamoon\", \"Morcos\", \"Atiyeh\", \"Isa\", \"Ba\", \"Baz\", \"Asker\", \"Seif\", \"Asghar\", \"Hajjar\", \"Deeb\", \n",
    "    \"Essa\", \"Qureshi\", \"Abboud\", \"Ganem\", \"Haddad\", \"Koury\", \"Nassar\", \"Abadi\", \"Toma\", \"Tannous\", \n",
    "    \"Harb\", \"Issa\", \"Khouri\", \"Mifsud\", \"Kalb\", \"Gaber\", \"Ganim\", \"Boulos\", \"Samaha\", \"Haddad\", \n",
    "    \"Sabbag\", \"Wasem\", \"Dagher\", \"Rahal\", \"Atiyeh\", \"Antar\", \"Asghar\", \"Mansour\", \"Awad\", \"Boulos\", \n",
    "    \"Sarraf\", \"Deeb\", \"Abadi\", \"Nazari\", \"Daher\", \"Gerges\", \"Shamoon\", \"Gaber\", \"Amari\", \"Sarraf\", \n",
    "    \"Nazari\", \"Saliba\", \"Naifeh\", \"Nazari\", \"Hakimi\", \"Shamon\", \"Abboud\", \"Quraishi\", \"Tahan\", \"Safar\", \n",
    "    \"Hajjar\", \"Srour\", \"Gaber\", \"Shalhoub\", \"Attia\", \"Safar\", \"Said\", \"Ganem\", \"Nader\", \"Asghar\", \n",
    "    \"Mustafa\", \"Said\", \"Antar\", \"Botros\", \"Nader\", \"Ghannam\", \"Asfour\", \"Tahan\", \"Mansour\", \"Attia\", \n",
    "    \"Touma\", \"Najjar\", \"Kassis\", \"Abboud\", \"Bishara\", \"Bazzi\", \"Shalhoub\", \"Shalhoub\", \"Safar\", \"Khoury\", \n",
    "    \"Nazari\", \"Sabbag\", \"Sleiman\", \"Atiyeh\", \"Kouri\", \"Bitar\", \"Zogby\", \"Ghanem\", \"Assaf\", \"Abadi\", \n",
    "    \"Arian\", \"Shalhoub\", \"Khoury\", \"Morcos\", \"Shamon\", \"Wasem\", \"Abadi\", \"Antoun\", \"Baz\", \"Naser\", \n",
    "    \"Assaf\", \"Saliba\", \"Nader\", \"Mikhail\", \"Naser\", \"Daher\", \"Morcos\", \"Awad\", \"Nahas\", \"Sarkis\", \n",
    "    \"Malouf\", \"Mustafa\", \"Fakhoury\", \"Ghannam\", \"Shadid\", \"Gaber\", \"Koury\", \"Atiyeh\", \"Shamon\", \"Boutros\", \n",
    "    \"Sarraf\", \"Arian\", \"Fakhoury\", \"Abadi\", \"Kassab\", \"Nahas\", \"Quraishi\", \"Mansour\", \"Samaha\", \"Wasem\", \n",
    "    \"Seif\", \"Fakhoury\", \"Saliba\", \"Cham\", \"Bahar\", \"Shamoun\", \"Essa\", \"Shamon\", \"Asfour\", \"Bitar\", \n",
    "    \"Cham\", \"Tahan\", \"Tannous\", \"Daher\", \"Khoury\", \"Shamon\", \"Bahar\", \"Quraishi\", \"Ghannam\", \"Kassab\", \n",
    "    \"Zogby\", \"Basara\", \"Shammas\", \"Arian\", \"Sayegh\", \"Naifeh\", \"Mifsud\", \"Sleiman\", \"Arian\", \"Kassis\", \n",
    "    \"Shamoun\", \"Kassis\", \"Harb\", \"Mustafa\", \"Boulos\", \"Asghar\", \"Shamon\", \"Kanaan\", \"Atiyeh\", \"Kassab\", \n",
    "    \"Tahan\", \"Bazzi\", \"Kassis\", \"Qureshi\", \"Basara\", \"Shalhoub\", \"Sayegh\", \"Haik\", \"Attia\", \"Maroun\", \n",
    "    \"Kassis\", \"Sarkis\", \"Harb\", \"Assaf\", \"Kattan\", \"Antar\", \"Sleiman\", \"Touma\", \"Sarraf\", \"Bazzi\", \n",
    "    \"Boulos\", \"Baz\", \"Issa\", \"Shamon\", \"Shadid\", \"Deeb\", \"Sabbag\", \"Wasem\", \"Awad\", \"Mansour\", \"Saliba\", \n",
    "    \"Fakhoury\", \"Arian\", \"Bishara\", \"Dagher\", \"Bishara\", \"Koury\", \"Fakhoury\", \"Naser\", \"Nader\", \"Antar\", \n",
    "    \"Gerges\", \"Handal\", \"Hanania\", \"Shadid\", \"Gerges\", \"Kassis\", \"Essa\", \"Assaf\", \"Shadid\", \"Seif\", \n",
    "    \"Shalhoub\", \"Shamoun\", \"Hajjar\", \"Baba\", \"Sayegh\", \"Mustafa\", \"Sabbagh\", \"Isa\", \"Najjar\", \"Tannous\", \n",
    "    \"Hanania\", \"Ganem\", \"Gerges\", \"Fakhoury\", \"Mifsud\", \"Nahas\", \"Bishara\", \"Bishara\", \"Abadi\", \"Sarkis\", \n",
    "    \"Masih\", \"Isa\", \"Attia\", \"Kalb\", \"Essa\", \"Boulos\", \"Basara\", \"Halabi\", \"Halabi\", \"Dagher\", \"Attia\", \n",
    "    \"Kassis\", \"Tuma\", \"Gerges\", \"Ghannam\", \"Toma\", \"Baz\", \"Asghar\", \"Zogby\", \"Aswad\", \"Hadad\", \"Dagher\", \n",
    "    \"Naser\", \"Shadid\", \"Atiyeh\", \"Zogby\", \"Abboud\", \"Tannous\", \"Khouri\", \"Atiyeh\", \"Ganem\", \"Maalouf\", \n",
    "    \"Isa\", \"Maroun\", \"Issa\", \"Khouri\", \"Harb\", \"Nader\", \"Awad\", \"Nahas\", \"Said\", \"Baba\", \"Totah\", \"Ganim\", \n",
    "    \"Handal\", \"Mansour\", \"Basara\", \"Malouf\", \"Said\", \"Botros\", \"Samaha\", \"Safar\", \"Tahan\", \"Botros\", \n",
    "    \"Shamoun\", \"Handal\", \"Sarraf\", \"Malouf\", \"Bishara\", \"Aswad\", \"Khouri\", \"Baz\", \"Asker\", \"Toma\", \n",
    "    \"Koury\", \"Gerges\", \"Bishara\", \"Boulos\", \"Najjar\", \"Aswad\", \"Shamon\", \"Kouri\", \"Srour\", \"Assaf\", \n",
    "    \"Tannous\", \"Attia\", \"Mustafa\", \"Kattan\", \"Asghar\", \"Amari\", \"Shadid\", \"Said\", \"Bazzi\", \"Masih\", \n",
    "    \"Antar\", \"Fakhoury\", \"Shadid\", \"Masih\", \"Handal\", \"Sarraf\", \"Kassis\", \"Salib\", \"Hajjar\", \"Totah\", \n",
    "    \"Koury\", \"Totah\", \"Mustafa\", \"Sabbagh\", \"Moghadam\", \"Toma\", \"Srour\", \"Almasi\", \"Totah\", \"Maroun\", \n",
    "    \"Kattan\", \"Naifeh\", \"Sarkis\", \"Mikhail\", \"Nazari\", \"Boutros\", \"Guirguis\", \"Gaber\", \"Kassis\", \"Masih\", \n",
    "    \"Hanania\", \"Maloof\", \"Quraishi\", \"Cham\", \"Hadad\", \"Tahan\", \"Bitar\", \"Arian\", \"Gaber\", \"Baz\", \n",
    "    \"Mansour\", \"Kalb\", \"Sarkis\", \"Attia\", \"Antar\", \"Asfour\", \"Said\", \"Essa\", \"Koury\", \"Hadad\", \"Tuma\", \n",
    "    \"Moghadam\", \"Sabbagh\", \"Amari\", \"Dagher\", \"Srour\", \"Antoun\", \"Sleiman\", \"Maroun\", \"Tuma\", \"Nahas\", \n",
    "    \"Hanania\", \"Sayegh\", \"Amari\", \"Sabbagh\", \"Said\", \"Cham\", \"Asker\", \"Nassar\", \"Bitar\", \"Said\", \"Dagher\", \n",
    "    \"Safar\", \"Khouri\", \"Totah\", \"Khoury\", \"Salib\", \"Basara\", \"Abboud\", \"Baz\", \"Isa\", \"Cham\", \"Amari\", \n",
    "    \"Mifsud\", \"Hadad\", \"Rahal\", \"Khoury\", \"Bazzi\", \"Basara\", \"Totah\", \"Ghannam\", \"Koury\", \"Malouf\", \n",
    "    \"Zogby\", \"Zogby\", \"Boutros\", \"Nassar\", \"Handal\", \"Hajjar\", \"Maloof\", \"Abadi\", \"Maroun\", \"Mifsud\", \n",
    "    \"Kalb\", \"Amari\", \"Hakimi\", \"Boutros\", \"Masih\", \"Kattan\", \"Haddad\", \"Arian\", \"Nazari\", \"Assaf\", \n",
    "    \"Attia\", \"Wasem\", \"Gerges\", \"Asker\", \"Tahan\", \"Fakhoury\", \"Shadid\", \"Sarraf\", \"Attia\", \"Naifeh\", \n",
    "    \"Aswad\", \"Deeb\", \"Tannous\", \"Totah\", \"Cham\", \"Baba\", \"Najjar\", \"Hajjar\", \"Shamoon\", \"Handal\", \n",
    "    \"Awad\", \"Guirguis\", \"Awad\", \"Ganem\", \"Naifeh\", \"Khoury\", \"Hajjar\", \"Moghadam\", \"Mikhail\", \"Ghannam\", \n",
    "    \"Guirguis\", \"Tannous\", \"Kanaan\", \"Handal\", \"Khoury\", \"Kalb\", \"Qureshi\", \"Najjar\", \"Atiyeh\", \"Gerges\", \n",
    "    \"Nassar\", \"Tahan\", \"Hadad\", \"Fakhoury\", \"Salib\", \"Wasem\", \"Bitar\", \"Fakhoury\", \"Attia\", \"Awad\", \n",
    "    \"Totah\", \"Deeb\", \"Touma\", \"Botros\", \"Nazari\", \"Nahas\", \"Kouri\", \"Ghannam\", \"Assaf\", \"Asfour\", \n",
    "    \"Sarraf\", \"Naifeh\", \"Toma\", \"Asghar\", \"Abboud\", \"Issa\", \"Sabbag\", \"Sabbagh\", \"Isa\", \"Koury\", \n",
    "    \"Kattan\", \"Shamoon\", \"Rahal\", \"Kalb\", \"Naser\", \"Masih\", \"Sayegh\", \"Dagher\", \"Asker\", \"Maroun\", \n",
    "    \"Dagher\", \"Sleiman\", \"Botros\", \"Sleiman\", \"Harb\", \"Tahan\", \"Tuma\", \"Said\", \"Hadad\", \"Samaha\", \n",
    "    \"Harb\", \"Cham\", \"Atiyeh\", \"Haik\", \"Malouf\", \"Bazzi\", \"Harb\", \"Malouf\", \"Ghanem\", \"Cham\", \"Asghar\", \n",
    "    \"Samaha\", \"Khouri\", \"Nassar\", \"Rahal\", \"Baz\", \"Kalb\", \"Rahal\", \"Gerges\", \"Cham\", \"Sayegh\", \n",
    "    \"Shadid\", \"Morcos\", \"Shamoon\", \"Hakimi\", \"Shamoon\", \"Qureshi\", \"Ganim\", \"Shadid\", \"Khoury\", \n",
    "    \"Boutros\", \"Hanania\", \"Antoun\", \"Naifeh\", \"Deeb\", \"Samaha\", \"Awad\", \"Asghar\", \"Awad\", \"Saliba\", \n",
    "    \"Shamoun\", \"Mikhail\", \"Hakimi\", \"Mikhail\", \"Cham\", \"Halabi\", \"Sarkis\", \"Kattan\", \"Nazari\", \n",
    "    \"Safar\", \"Morcos\", \"Khoury\", \"Essa\", \"Nassar\", \"Haik\", \"Shadid\", \"Fakhoury\", \"Najjar\", \"Arian\", \n",
    "    \"Botros\", \"Daher\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3137854b-076e-47a7-aa89-d880b7a8ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_names = [\n",
    "    \"Abel\", \"Abraham\", \"Adam\", \"Albert\", \"Allard\", \"Archambault\", \"Armistead\", \"Arthur\", \"Augustin\", \n",
    "    \"Babineaux\", \"Baudin\", \"Beauchene\", \"Beaulieu\", \"Beaumont\", \"Bélanger\", \"Bellamy\", \"Bellerose\", \n",
    "    \"Belrose\", \"Berger\", \"Béringer\", \"Bernard\", \"Bertrand\", \"Bisset\", \"Bissette\", \"Blaise\", \"Blanc\", \n",
    "    \"Blanchet\", \"Blanchett\", \"Bonfils\", \"Bonheur\", \"Bonhomme\", \"Bonnaire\", \"Bonnay\", \"Bonner\", \n",
    "    \"Bonnet\", \"Borde\", \"Bordelon\", \"Bouchard\", \"Boucher\", \"Brisbois\", \"Brodeur\", \"Bureau\", \"Caron\", \n",
    "    \"Cavey\", \"Chaput\", \"Charbonneau\", \"Charpentier\", \"Charron\", \"Chastain\", \"Chevalier\", \"Chevrolet\", \n",
    "    \"Cloutier\", \"Colbert\", \"Comtois\", \"Cornett\", \"Coté\", \"Coupe\", \"Courtemanche\", \"Cousineau\", \n",
    "    \"Couture\", \"Daniau\", \"D'aramitz\", \"Daviau\", \"David\", \"Deforest\", \"Degarmo\", \"Delacroix\", \n",
    "    \"De la fontaine\", \"Deniau\", \"Deniaud\", \"Deniel\", \"Denis\", \"De sauveterre\", \"Deschamps\", \n",
    "    \"Descoteaux\", \"Desjardins\", \"Desrochers\", \"Desrosiers\", \"Dubois\", \"Duchamps\", \"Dufort\", \"Dufour\", \n",
    "    \"Duguay\", \"Dupond\", \"Dupont\", \"Durand\", \"Durant\", \"Duval\", \"Émile\", \"Eustis\", \"Fabian\", \"Fabre\", \n",
    "    \"Fabron\", \"Faucher\", \"Faucheux\", \"Faure\", \"Favager\", \"Favre\", \"Favreau\", \"Fay\", \"Félix\", \"Firmin\", \n",
    "    \"Fontaine\", \"Forest\", \"Forestier\", \"Fortier\", \"Foss\", \"Fournier\", \"Gage\", \"Gagne\", \"Gagnier\", \n",
    "    \"Gagnon\", \"Garcon\", \"Gardinier\", \"Germain\", \"Géroux\", \"Giles\", \"Girard\", \"Giroux\", \"Glaisyer\", \n",
    "    \"Gosse\", \"Gosselin\", \"Granger\", \"Guérin\", \"Guillory\", \"Hardy\", \"Harman\", \"Hébert\", \"Herbert\", \n",
    "    \"Herriot\", \"Jacques\", \"Janvier\", \"Jordan\", \"Joubert\", \"Labelle\", \"Lachance\", \"Lachapelle\", \n",
    "    \"Lamar\", \"Lambert\", \"Lane\", \"Langlais\", \"Langlois\", \"Lapointe\", \"Larue\", \"Laurent\", \"Lavigne\", \n",
    "    \"Lavoie\", \"Leandres\", \"Lebeau\", \"Leblanc\", \"Leclair\", \"Leclerc\", \"Lécuyer\", \"Lefebvre\", \n",
    "    \"Lefévre\", \"Lefurgey\", \"Legrand\", \"Lemaire\", \"Lémieux\", \"Leon\", \"Leroy\", \"Lesauvage\", \n",
    "    \"Lestrange\", \"Lévêque\", \"Lévesque\", \"Linville\", \"Lyon\", \"Lyon\", \"Maçon\", \"Marchand\", \"Marie\", \n",
    "    \"Marion\", \"Martel\", \"Martel\", \"Martin\", \"Masson\", \"Masson\", \"Mathieu\", \"Mercier\", \"Merle\", \n",
    "    \"Michaud\", \"Michel\", \"Monet\", \"Monette\", \"Montagne\", \"Moreau\", \"Moulin\", \"Mullins\", \"Noel\", \n",
    "    \"Oliver\", \"Olivier\", \"Page\", \"Paget\", \"Palomer\", \"Pan\", \"Pape\", \"Paquet\", \"Paquet\", \"Parent\", \n",
    "    \"Paris\", \"Parris\", \"Pascal\", \"Patenaude\", \"Paternoster\", \"Paul\", \"Pelletier\", \"Perrault\", \n",
    "    \"Perreault\", \"Perrot\", \"Petit\", \"Pettigrew\", \"Pierre\", \"Plamondon\", \"Plourde\", \"Poingdestre\", \n",
    "    \"Poirier\", \"Porcher\", \"Poulin\", \"Proulx\", \"Renaud\", \"Rey\", \"Reyer\", \"Richard\", \"Richelieu\", \n",
    "    \"Robert\", \"Roche\", \"Rome\", \"Romilly\", \"Rose\", \"Rousseau\", \"Roux\", \"Roy\", \"Royer\", \"Salomon\", \n",
    "    \"Salvage\", \"Samson\", \"Samuel\", \"Sargent\", \"Sarkozi\", \"Sarkozy\", \"Sartre\", \"Sault\", \"Sauvage\", \n",
    "    \"Sauvageau\", \"Sauvageon\", \"Sauvageot\", \"Sauveterre\", \"Savatier\", \"Segal\", \"Sergeant\", \n",
    "    \"Séverin\", \"Simon\", \"Solomon\", \"Soucy\", \"St martin\", \"St pierre\", \"Tailler\", \"Tasse\", \n",
    "    \"Thayer\", \"Thibault\", \"Thomas\", \"Tobias\", \"Tolbert\", \"Traver\", \"Travere\", \"Travers\", \"Traverse\", \n",
    "    \"Travert\", \"Tremblay\", \"Tremble\", \"Victor\", \"Victors\", \"Villeneuve\", \"Vincent\", \"Vipond\", \n",
    "    \"Voclain\", \"Yount\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28c0ba45-7d49-4c5f-a320-ed4d9fc8f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_names = [\n",
    "    \"Ababko\", \"Abaev\", \"Abagyan\", \"Abaidulin\", \"Abaidullin\", \"Abaimoff\", \n",
    "    \"Abaimov\", \"Abakeliya\", \"Abakovsky\", \"Abakshin\", \"Abakumoff\", \"Abakumov\",\n",
    "    \"Abakumtsev\", \"Abakushin\", \"Abalakin\", \"Abalakoff\", \"Abalakov\", \"Abaleshev\",\n",
    "    \"Abalihin\", \"Abalikhin\", \"Abalkin\", \"Abalmasoff\", \"Abalmasov\", \"Abaloff\",\n",
    "    \"Abalov\", \"Abamelek\", \"Abanin\", \"Abankin\", \"Abarinoff\", \"Abarinov\",\n",
    "    \"Abasheev\", \"Abashev\", \"Abashidze\", \"Abashin\", \"Abashkin\", \"Abasov\",\n",
    "    \"Abatsiev\", \"Abaturoff\", \"Abaturov\", \"Abaza\", \"Abaziev\", \"Abbakumov\",\n",
    "    \"Abbakumovsky\", \"Abbasov\", \"Abdank-Kossovsky\", \"Abdeev\", \"Abdildin\",\n",
    "    \"Abdrahimoff\", \"Abdrahimov\", \"Abdrahmanoff\", \"Abdrahmanov\", \"Abdrakhimoff\",\n",
    "    \"Abdrakhimov\", \"Abdrakhmanoff\", \"Abdrakhmanov\", \"Abdrashitoff\", \"Abdrashitov\",\n",
    "    \"Abdrazakoff\", \"Abdrazakov\", \"Abdulaev\", \"Abdulatipoff\", \"Abdulatipov\",\n",
    "    \"Abdulazizoff\", \"Abdulazizov\", \"Abdulbasiroff\", \"Abdulbasirov\", \"Abdulbekoff\",\n",
    "    \"Abdulbekov\", \"Abdulgapuroff\", \"Abdulgapurov\", \"Abdulgaziev\", \"Abdulhabiroff\",\n",
    "    \"Abdulhabirov\", \"Abdulin\", \"Abdulkadyroff\", \"Abdulkadyrov\", \"Abdulkhabiroff\",\n",
    "    \"Abdulkhabirov\", \"Abdulladjanov\", \"Abdulladzhanoff\", \"Abdulladzhanov\", \"Abdullaev\",\n",
    "    \"Abdullin\", \"Abduloff\", \"Abdulov\", \"Abdulrahmanoff\", \"Abdulrahmanov\",\n",
    "    \"Abdulrakhmanoff\", \"Abdulrakhmanov\", \"Abdurahmanoff\", \"Abdurahmanov\", \"Abdurakhmanoff\",\n",
    "    \"Abdurakhmanov\", \"Abegyan\", \"Abel\", \"Abeldyaev\", \"Abelev\", \"Abelman\",\n",
    "    \"Abelmazoff\", \"Abelmazov\", \"Abels\", \"Abelsky\", \"Abeltsev\", \"Abelyan\",\n",
    "    \"Aberson\", \"Abertasov\", \"Abesadze\", \"Abezgauz\", \"Abgaryan\", \"Abibulaev\",\n",
    "    \"Abidoff\", \"Abidov\", \"Abih\", \"Abikh\", \"Abisaloff\", \"Abisalov\",\n",
    "    \"Abitoff\", \"Abitov\", \"Abjaliloff\", \"Abjalilov\", \"Abkin\", \"Ablaev\",\n",
    "    \"Ablesimoff\", \"Ablesimov\", \"Abletsoff\", \"Abletsov\", \"Ableuhoff\", \"Ableuhov\",\n",
    "    \"Ableukhoff\", \"Ableukhov\", \"Abloff\", \"Ablov\", \"Ablyakimoff\", \"Ablyakimov\",\n",
    "    \"Ablyazov\", \"Aboev\", \"Aboff\", \"Aboimoff\", \"Aboimov\", \"Abolihin\",\n",
    "    \"Abolikhin\", \"Abolin\", \"Abolins\", \"Abov\", \"Abovin\", \"Abovyan\",\n",
    "    \"Aboyantsev\", \"Abragam\", \"Abragamson\", \"Abrahimoff\", \"Abrahimov\", \"Abrajevich\",\n",
    "    \"Abrakhimoff\", \"Abrakhimov\", \"Abramchikoff\", \"Abramchikov\", \"Abramchuk\", \"Abrameitsev\",\n",
    "    \"Abramenko\", \"Abramenkoff\", \"Abramenkov\", \"Abramkoff\", \"Abramkov\", \"Abramoff\",\n",
    "    \"Abramov\", \"Abramovich\", \"Abramovitch\", \"Abramovsky\", \"Abramowich\", \"Abramowitch\",\n",
    "    \"Abramowsky\", \"Abramson\", \"Abramtchikoff\", \"Abramtchikov\", \"Abramtchuk\", \"Abramtsev\",\n",
    "    \"Abramyan\", \"Abraroff\", \"Abrarov\", \"Abrashin\", \"Abrashitov\", \"Abrasimoff\",\n",
    "    \"Abrasimov\", \"Abrazhevich\", \"Abrikosoff\", \"Abrikosov\", \"Abrosimoff\", \"Abrosimov\",\n",
    "    \"Abroskin\", \"Abrosoff\", \"Abrosov\", \"Abrukov\", \"Absalyamoff\", \"Absalyamov\",\n",
    "    \"Absattaroff\", \"Absattarov\", \"Abubakiroff\", \"Abubakirov\", \"Abubekeroff\", \"Abubekerov\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0beaa2a7-1d00-45ea-877c-38638b90bcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "viet_name = [\n",
    "    \"Nguyen\", \"Tron\", \"Le\", \"Pham\", \"Huynh\", \"Hoang\", \"Phan\", \"Vu\", \"Vo\", \"Dang\", \n",
    "    \"Bui\", \"Do\", \"Ho\", \"Ngo\", \"Duong\", \"Ly\", \"An\", \"an\", \"Bach\", \"Banh\", \"Cao\", \n",
    "    \"Chau\", \"Chu\", \"Chung\", \"Chu\", \"Diep\", \"Doan\", \"Dam\", \"Dao\", \"Dinh\", \"Doan\", \n",
    "    \"Giang\", \"Ha\", \"Han\", \"Kieu\", \"Kim\", \"La\", \"Lac\", \"Lam\", \"Lieu\", \"Luc\", \n",
    "    \"Luong\", \"Luu\", \"Ma\", \"Mach\", \"Mai\", \"Nghiem\", \"Phi\", \"Pho\", \"Phung\", \n",
    "    \"Quach\", \"Quang\", \"Quyen\", \"Ta\", \"Thach\", \"Thai\", \"Sai\", \"Thi\", \"Than\", \n",
    "    \"Thao\", \"Thuy\", \"Tieu\", \"To\", \"Ton\", \"Tong\", \"Trang\", \"Trieu\", \"Trinh\", \n",
    "    \"Truong\", \"Van\", \"Vinh\", \"Vuong\", \"Vuu\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fcec9bd1-b589-477e-b968-378ccdd2f389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018050541516245487\n"
     ]
    }
   ],
   "source": [
    "true = 0\n",
    "wrong = 0\n",
    "for name in french_names:\n",
    "    res = predict(name)\n",
    "    if res == 'French':\n",
    "        true +=1\n",
    "    else:\n",
    "        wrong +=1\n",
    "        \n",
    "print((true / (true+wrong)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cab2dfd-2e38-40ce-a2e2-5662d5bcd30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbdb6f0-488a-4ebd-8f66-f705c28cbb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3fb66b-1594-4592-9a06-65fecc907035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20a2560-1f61-44e5-bc97-27867766c287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all_purpose_venv",
   "language": "python",
   "name": "all_purpose_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
