{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simple terms: The model learns vector representations for words by predicting their co-occurrence relationships as described by the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "J = \\sum_{i,j} f(X_{ij}) \\left( w_i^\\top w_j + b_i + b_j - \\log X_{ij} \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gap between the prediction and the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left( w_i^\\top w_j + b_i + b_j - \\log X_{ij} \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighting function that adjusts how much importance is given to each word pair (i,j) based on their co-occurrence frequency. The calculation is the amount of co-occurence / some hyperparameter (typically 10). The result is raised to the power of another hyper parameter, typically 0.75"
   ]
  },
  {
   "attachments": {
    "3d0acdb9-5834-4e2b-ba0e-792c52f268a3.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:3d0acdb9-5834-4e2b-ba0e-792c52f268a3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Xmax -  limits the impact of very frequent co-occurrences, preventing them from dominating trainingabs\n",
    "* alpha - balances the scaling of weights, giving less frequent pairs a fair impact without overemphasizing rare ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(X_{ij})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"gutenberg\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-16T12:55:28.289835Z",
     "iopub.status.busy": "2025-01-16T12:55:28.289550Z",
     "iopub.status.idle": "2025-01-16T12:55:28.765083Z",
     "shell.execute_reply": "2025-01-16T12:55:28.764094Z",
     "shell.execute_reply.started": "2025-01-16T12:55:28.289813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to /usr/share/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "Sample preprocessed sentence: [['emma', 'by', 'jane', 'austen']]\n"
     ]
    }
   ],
   "source": [
    "corpus = nltk.corpus.gutenberg.sents(\"austen-emma.txt\")\n",
    "\n",
    "corpus = [preprocess(sentence) for sentence in corpus]\n",
    "tokenized_corpus = [sentence.split() for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    sentence = \" \".join(sentence).lower()  # Lowercase\n",
    "    sentence = re.sub(r\"[^a-z\\s]\", \"\", sentence)  # Remove punctuation\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(word for sentence in tokenized_corpus for word in sentence)\n",
    "vocab_size = len(vocab)\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T12:57:50.794133Z",
     "iopub.status.busy": "2025-01-16T12:57:50.793750Z",
     "iopub.status.idle": "2025-01-16T12:57:52.741127Z",
     "shell.execute_reply": "2025-01-16T12:57:52.740177Z",
     "shell.execute_reply.started": "2025-01-16T12:57:50.794099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-occurrence matrix shape: (7096, 7096)\n",
      "CPU times: user 1.77 s, sys: 170 ms, total: 1.94 s\n",
      "Wall time: 1.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build the co-occurrence matrix\n",
    "window_size = 2\n",
    "co_occurrence_matrix = np.zeros((vocab_size, vocab_size), dtype=np.float32)\n",
    "\n",
    "for sentence in tokenized_corpus:\n",
    "    for idx, word in enumerate(sentence):\n",
    "        word_idx = word_to_idx[word]\n",
    "        start = max(idx - window_size, 0)\n",
    "        end = min(idx + window_size + 1, len(sentence))\n",
    "        for context_word in sentence[start:end]:\n",
    "            if context_word != word:\n",
    "                context_idx = word_to_idx[context_word]\n",
    "                co_occurrence_matrix[word_idx, context_idx] += 1\n",
    "\n",
    "print(\"Co-occurrence matrix shape:\", co_occurrence_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:01:45.409674Z",
     "iopub.status.busy": "2025-01-16T13:01:45.409387Z",
     "iopub.status.idle": "2025-01-16T13:01:45.414551Z",
     "shell.execute_reply": "2025-01-16T13:01:45.413705Z",
     "shell.execute_reply.started": "2025-01-16T13:01:45.409651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' emma by jane austen  '"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:01:49.305241Z",
     "iopub.status.busy": "2025-01-16T13:01:49.304954Z",
     "iopub.status.idle": "2025-01-16T13:01:49.309955Z",
     "shell.execute_reply": "2025-01-16T13:01:49.309273Z",
     "shell.execute_reply.started": "2025-01-16T13:01:49.305220Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7752"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:04:50.277638Z",
     "iopub.status.busy": "2025-01-16T13:04:50.277330Z",
     "iopub.status.idle": "2025-01-16T13:04:50.283725Z",
     "shell.execute_reply": "2025-01-16T13:04:50.282988Z",
     "shell.execute_reply.started": "2025-01-16T13:04:50.277615Z"
    }
   },
   "outputs": [],
   "source": [
    "class GloVe(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(GloVe, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.word_biases = nn.Embedding(vocab_size, 1)\n",
    "        self.context_biases = nn.Embedding(vocab_size, 1)\n",
    "\n",
    "        # Initialize weights\n",
    "        nn.init.xavier_uniform_(self.word_embeddings.weight)\n",
    "        nn.init.xavier_uniform_(self.context_embeddings.weight)\n",
    "        nn.init.zeros_(self.word_biases.weight)\n",
    "        nn.init.zeros_(self.context_biases.weight)\n",
    "\n",
    "    def forward(self, word_idx, context_idx):\n",
    "        word_embed = self.word_embeddings(word_idx)\n",
    "        context_embed = self.context_embeddings(context_idx)\n",
    "        word_bias = self.word_biases(word_idx).squeeze()\n",
    "        context_bias = self.context_biases(context_idx).squeeze()\n",
    "        \n",
    "        # Dot product + biases\n",
    "        prediction = (word_embed * context_embed).sum(dim=1) + word_bias + context_bias\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:09:37.602528Z",
     "iopub.status.busy": "2025-01-16T13:09:37.602210Z",
     "iopub.status.idle": "2025-01-16T13:09:37.608547Z",
     "shell.execute_reply": "2025-01-16T13:09:37.607721Z",
     "shell.execute_reply.started": "2025-01-16T13:09:37.602504Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class GloVe(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(GloVe, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.word_biases = nn.Embedding(vocab_size, 1)\n",
    "        self.context_biases = nn.Embedding(vocab_size, 1)\n",
    "\n",
    "        # Initialize weights\n",
    "        nn.init.uniform_(self.word_embeddings.weight, a=-0.5, b=0.5)  \n",
    "        nn.init.uniform_(self.context_embeddings.weight, a=-0.5, b=0.5)\n",
    "        nn.init.zeros_(self.word_biases.weight)\n",
    "        nn.init.zeros_(self.context_biases.weight)\n",
    "\n",
    "    def forward(self, word_idx, context_idx):\n",
    "        word_embed = self.word_embeddings(word_idx)\n",
    "        context_embed = self.context_embeddings(context_idx)\n",
    "        word_bias = self.word_biases(word_idx).squeeze()\n",
    "        context_bias = self.context_biases(context_idx).squeeze()\n",
    "        \n",
    "        # Dot product + biases\n",
    "        prediction = (word_embed * context_embed).sum(dim=1) + word_bias + context_bias\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:09:37.760242Z",
     "iopub.status.busy": "2025-01-16T13:09:37.759957Z",
     "iopub.status.idle": "2025-01-16T13:09:37.764793Z",
     "shell.execute_reply": "2025-01-16T13:09:37.763869Z",
     "shell.execute_reply.started": "2025-01-16T13:09:37.760220Z"
    }
   },
   "outputs": [],
   "source": [
    "def weighting_function(x, X_max=100, alpha=0.75):\n",
    "    return torch.where(x < X_max, (x / X_max) ** alpha, torch.ones_like(x))\n",
    "\n",
    "def glove_loss(prediction, log_co_occurrence, weights):\n",
    "    return torch.sum(weights * (prediction - log_co_occurrence) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:21:56.127770Z",
     "iopub.status.busy": "2025-01-16T13:21:56.127447Z",
     "iopub.status.idle": "2025-01-16T13:21:56.174833Z",
     "shell.execute_reply": "2025-01-16T13:21:56.174159Z",
     "shell.execute_reply.started": "2025-01-16T13:21:56.127747Z"
    }
   },
   "outputs": [],
   "source": [
    "co_occurrence = torch.tensor(co_occurrence_matrix, dtype=torch.float32, device=device)\n",
    "log_co_occurrence = torch.log(co_occurrence + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor([1, 1, 0, 0])\n",
    "torch.nonzero(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:21:56.335668Z",
     "iopub.status.busy": "2025-01-16T13:21:56.335369Z",
     "iopub.status.idle": "2025-01-16T13:21:56.340342Z",
     "shell.execute_reply": "2025-01-16T13:21:56.339589Z",
     "shell.execute_reply.started": "2025-01-16T13:21:56.335644Z"
    }
   },
   "outputs": [],
   "source": [
    "# torch.nonzero is a PyTorch function that returns the indices of all non-zero elements in a tensor.\n",
    "word_indices, context_indices = torch.nonzero(co_occurrence, as_tuple=True)\n",
    "co_occurrence_values = co_occurrence[word_indices, context_indices]\n",
    "weights = weighting_function(co_occurrence_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:21:57.512414Z",
     "iopub.status.busy": "2025-01-16T13:21:57.512120Z",
     "iopub.status.idle": "2025-01-16T13:21:57.540628Z",
     "shell.execute_reply": "2025-01-16T13:21:57.539731Z",
     "shell.execute_reply.started": "2025-01-16T13:21:57.512389Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize model and optimizer\n",
    "embedding_dim = 100\n",
    "model = GloVe(vocab_size, embedding_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:21:58.011128Z",
     "iopub.status.busy": "2025-01-16T13:21:58.010783Z",
     "iopub.status.idle": "2025-01-16T13:21:58.676822Z",
     "shell.execute_reply": "2025-01-16T13:21:58.675912Z",
     "shell.execute_reply.started": "2025-01-16T13:21:58.011102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 30280.5625\n",
      "Epoch 20, Loss: 6990.6714\n",
      "Epoch 30, Loss: 3633.1284\n",
      "Epoch 40, Loss: 2244.1128\n",
      "Epoch 50, Loss: 1368.1260\n",
      "Epoch 60, Loss: 1028.3760\n",
      "Epoch 70, Loss: 811.9969\n",
      "Epoch 80, Loss: 670.2060\n",
      "Epoch 90, Loss: 568.6556\n",
      "Epoch 100, Loss: 492.0566\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    predictions = model(word_indices, context_indices)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = glove_loss(predictions, log_co_occurrence[word_indices, context_indices], weights)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:21:58.678386Z",
     "iopub.status.busy": "2025-01-16T13:21:58.678023Z",
     "iopub.status.idle": "2025-01-16T13:21:58.686952Z",
     "shell.execute_reply": "2025-01-16T13:21:58.686180Z",
     "shell.execute_reply.started": "2025-01-16T13:21:58.678348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Similarities:\n",
      "Similarity between 'king' and 'queen': 0.0215\n",
      "Similarity between 'man' and 'woman': 0.4022\n",
      "Words 'deep' or 'learning' not in vocabulary.\n",
      "Words 'fun' or 'amazing' not in vocabulary.\n"
     ]
    }
   ],
   "source": [
    "# Extract embeddings\n",
    "word_embeddings = model.word_embeddings.weight.detach().cpu().numpy()\n",
    "\n",
    "# Cosine similarity function\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Test pairs\n",
    "test_pairs = [(\"king\", \"queen\"), (\"man\", \"woman\"), (\"deep\", \"learning\"), (\"fun\", \"amazing\")]\n",
    "\n",
    "print(\"\\nCosine Similarities:\")\n",
    "for word1, word2 in test_pairs:\n",
    "    if word1 in word_to_idx and word2 in word_to_idx:\n",
    "        vec1 = word_embeddings[word_to_idx[word1]]\n",
    "        vec2 = word_embeddings[word_to_idx[word2]]\n",
    "        sim = cosine_similarity(vec1, vec2)\n",
    "        print(f\"Similarity between '{word1}' and '{word2}': {sim:.4f}\")\n",
    "    else:\n",
    "        print(f\"Words '{word1}' or '{word2}' not in vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T12:36:00.752931Z",
     "iopub.status.busy": "2025-01-16T12:36:00.752593Z",
     "iopub.status.idle": "2025-01-16T12:36:00.760914Z",
     "shell.execute_reply": "2025-01-16T12:36:00.760223Z",
     "shell.execute_reply.started": "2025-01-16T12:36:00.752895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Similarities:\n",
      "Similarity between 'king' and 'queen': 0.3132\n",
      "Similarity between 'man' and 'woman': 0.5327\n",
      "Words 'deep' or 'learning' not in vocabulary.\n",
      "Words 'fun' or 'amazing' not in vocabulary.\n"
     ]
    }
   ],
   "source": [
    "# Extract embeddings\n",
    "word_embeddings = model.word_embeddings.weight.detach().cpu().numpy()\n",
    "\n",
    "# Cosine similarity function\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Test pairs\n",
    "test_pairs = [(\"king\", \"queen\"), (\"man\", \"woman\"), (\"deep\", \"learning\"), (\"fun\", \"amazing\")]\n",
    "\n",
    "print(\"\\nCosine Similarities:\")\n",
    "for word1, word2 in test_pairs:\n",
    "    if word1 in word_to_idx and word2 in word_to_idx:\n",
    "        vec1 = word_embeddings[word_to_idx[word1]]\n",
    "        vec2 = word_embeddings[word_to_idx[word2]]\n",
    "        sim = cosine_similarity(vec1, vec2)\n",
    "        print(f\"Similarity between '{word1}' and '{word2}': {sim:.4f}\")\n",
    "    else:\n",
    "        print(f\"Words '{word1}' or '{word2}' not in vocabulary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T12:36:44.101184Z",
     "iopub.status.busy": "2025-01-16T12:36:44.100847Z",
     "iopub.status.idle": "2025-01-16T12:36:44.110592Z",
     "shell.execute_reply": "2025-01-16T12:36:44.109699Z",
     "shell.execute_reply.started": "2025-01-16T12:36:44.101158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Similarities:\n",
      "Similarity between 'king' and 'queen': 0.3152\n",
      "Similarity between 'man' and 'woman': 0.4924\n"
     ]
    }
   ],
   "source": [
    "# Extract embeddings\n",
    "word_embeddings = model.word_embeddings.weight.detach().cpu().numpy()\n",
    "\n",
    "# Cosine similarity function\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Test pairs\n",
    "test_pairs = [(\"king\", \"queen\"), (\"man\", \"woman\")]\n",
    "\n",
    "print(\"\\nCosine Similarities:\")\n",
    "for word1, word2 in test_pairs:\n",
    "    if word1 in word_to_idx and word2 in word_to_idx:\n",
    "        vec1 = word_embeddings[word_to_idx[word1]]\n",
    "        vec2 = word_embeddings[word_to_idx[word2]]\n",
    "        sim = cosine_similarity(vec1, vec2)\n",
    "        print(f\"Similarity between '{word1}' and '{word2}': {sim:.4f}\")\n",
    "    else:\n",
    "        print(f\"Words '{word1}' or '{word2}' not in vocabulary.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline\n",
    "\\textbf{Aspect} & \\textbf{GloVe} & \\textbf{Word2Vec} \\\\\n",
    "\\hline\n",
    "\\textbf{Training Approach} & \\text{Uses a co-occurrence matrix and matrix factorization.} & \\text{Predictive model using CBOW or Skip-Gram.} \\\\\n",
    "\\hline\n",
    "\\textbf{Data Utilization} & \\text{Leverages entire corpus statistics for global context.} & \\text{Processes word pairs iteratively in local contexts.} \\\\\n",
    "\\hline\n",
    "\\textbf{Training Efficiency} & \\text{Slower due to large co-occurrence matrix decomposition.} & \\text{Faster with a simpler predictive model.} \\\\\n",
    "\\hline\n",
    "\\textbf{Representation} & \\text{Captures global semantic relationships.} & \\text{Focuses on local contextual similarities.} \\\\\n",
    "\\hline\n",
    "\\textbf{Memory Usage} & \\text{Requires more memory for storing a co-occurrence matrix.} & \\text{Less memory-intensive with dynamic processing.} \\\\\n",
    "\\hline\n",
    "\\textbf{Performance} & \\text{Excels in analogy and word similarity tasks.} & \\text{Captures context-specific meanings better.} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:49:37.714727Z",
     "iopub.status.busy": "2025-01-16T13:49:37.714423Z",
     "iopub.status.idle": "2025-01-16T13:49:37.718082Z",
     "shell.execute_reply": "2025-01-16T13:49:37.717232Z",
     "shell.execute_reply.started": "2025-01-16T13:49:37.714705Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:47:05.701098Z",
     "iopub.status.busy": "2025-01-16T13:47:05.700709Z",
     "iopub.status.idle": "2025-01-16T13:47:07.391918Z",
     "shell.execute_reply": "2025-01-16T13:47:07.390929Z",
     "shell.execute_reply.started": "2025-01-16T13:47:05.701045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.3446    1.0975   -4.6895   -8.4208   -3.6353   -0.24038   6.6428\n",
      "  1.6418    0.49773  -6.321     1.6186   -0.5861    0.63108  -0.24744\n",
      "  0.29919  -3.8426    4.2843    2.1738    0.41612   3.1827    3.2224\n",
      "  5.0443    0.72128  -4.7134   -4.0458    2.1136   -2.8936   -0.42879\n",
      " -0.69461   2.3631   -2.8901    4.7581    2.6114    1.0457   -1.6006\n",
      "  3.7869   -1.0832    1.9244    0.38682  -3.2681   -2.7907   -1.8807\n",
      "  0.2354    1.0458    3.4776   -1.1807   -3.6822   -4.3433    3.8024\n",
      "  3.3623    0.24533   1.1       4.9555    0.17855  -4.2763   -1.8527\n",
      " -0.21801  -3.5733    2.3128    4.8652   -0.17878   2.6503   -3.8391\n",
      "  1.5403   -0.26942   3.997    -9.1952   -2.2391   -3.4958   -2.4144\n",
      " -5.3832    2.3918   -5.2075   -3.3855    4.1362    0.6631    3.3512\n",
      "  0.39198   1.0602    2.2332    1.4476    2.8263    5.2858   -1.015\n",
      "  1.5394   -2.7863    4.6867    0.44141  -4.1558    2.8847   -4.1582\n",
      "  6.9774    1.5895   -1.9002   -0.06736  -5.3914    4.8448   -2.7114\n",
      "  1.5776    0.93064  -0.20705  -3.7003    1.7374    3.7324   -2.7058\n",
      " -3.4788    0.057588  1.7023    1.0894   -0.27457   4.0505    3.6853\n",
      " -0.017283  1.9409    1.9349   -1.4144   -5.7805   -4.5333    1.1371\n",
      " -0.99614   0.35502  -2.1938    5.955     4.7354   -5.7262    0.51219\n",
      "  1.6325   -3.985    -4.0765    5.5784   -2.2584    4.1271    1.5502\n",
      " -0.51632  -3.3936    0.97601  -1.4152    0.28975   1.8619   -3.2033\n",
      " -1.2717    2.2185    0.095118  0.35704  -1.863     1.2896   -2.9584\n",
      " -3.2596   -0.48908   1.4207    0.30852  -0.13401   3.1326    1.6557\n",
      " -2.4326    0.43266   4.6182    6.0219   -1.0798    3.2285    3.3881\n",
      " -2.4416   -0.45764  -1.5855   -1.6538   -4.4133    5.0546   -5.1137\n",
      " -5.3472   -3.5091    1.4229   -2.0854   -2.086     0.45246  -3.5471\n",
      " -0.43447   2.181     1.3555    0.39038  -0.42925  -1.1838    2.7577\n",
      " -1.6251    0.68686  -0.86205   1.5082   -0.57147  -0.73016   0.99762\n",
      " -0.64492   0.86545   3.2855    0.73931   0.40366   2.5894   -6.9524\n",
      " -5.1777    2.7262   -2.1877    9.5222    0.33268   0.90443  -3.241\n",
      "  2.0325   -0.92257   1.941     1.8899    1.7556   -2.2246    0.64504\n",
      "  5.1676   -6.9524    3.4669    3.9617    4.9852    1.3811   -3.2955\n",
      " -1.41     -2.3149   -1.7093   -0.4401   -7.013     2.1466    5.4878\n",
      " -0.74644   1.4045    0.074977  0.9044   -2.0775   -0.56121  -1.8377\n",
      "  0.2872    3.9989    2.5705    0.40557   2.9427    2.7607    4.498\n",
      " -2.7501   -0.16241  -1.8828   -3.0114   -3.7455   -1.3457    4.1817\n",
      " -5.8448    0.38745  -3.2207    0.077698  3.4284    2.6129   -2.4162\n",
      " -2.4816   -3.2025   -3.2488    3.8175    2.2502    1.6198   -0.58931\n",
      "  3.7041    0.10122  -1.6063    0.86988  -2.2578   -5.5716   -3.3934\n",
      " -0.64469   3.5592   -1.5831   -4.8981   -2.7986   -3.3026   -1.516\n",
      "  0.072117  0.048913  0.73591   0.80361   1.6729   -2.8863    0.15578\n",
      " -5.6245   -4.7372    0.13569   1.9637    6.122    -0.14256   0.69751\n",
      " -1.3558    1.0917    1.1069    0.45539  -8.5174    6.5622   -0.60295\n",
      " -4.1502   -1.2302    4.4608   -0.06849  -4.1377    0.27519 ]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English medium model with word vectors\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "# Access word vectors\n",
    "movie_vector = nlp('movie').vector\n",
    "print(movie_vector)  # GloVe-like embedding for \"movie\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:47:59.697453Z",
     "iopub.status.busy": "2025-01-16T13:47:59.697101Z",
     "iopub.status.idle": "2025-01-16T13:47:59.701436Z",
     "shell.execute_reply": "2025-01-16T13:47:59.700613Z",
     "shell.execute_reply.started": "2025-01-16T13:47:59.697424Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"I love this movie!\", \"positive\"),\n",
    "    (\"This is the worst film Iâ€™ve ever seen.\", \"negative\"),\n",
    "    (\"Absolutely fantastic experience.\", \"positive\"),\n",
    "    (\"I hated it. Total waste of time.\", \"negative\"),\n",
    "    (\"The plot was amazing and I enjoyed it a lot.\", \"positive\"),\n",
    "    (\"Terrible acting and boring story.\", \"negative\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:48:01.475364Z",
     "iopub.status.busy": "2025-01-16T13:48:01.475054Z",
     "iopub.status.idle": "2025-01-16T13:48:01.530555Z",
     "shell.execute_reply": "2025-01-16T13:48:01.529852Z",
     "shell.execute_reply.started": "2025-01-16T13:48:01.475342Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create features (vectors) and labels\n",
    "X = [nlp(text).vector for text, label in data]\n",
    "y = [1 if label == \"positive\" else 0 for _, label in data]  # 1 = positive, 0 = negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:48:15.585092Z",
     "iopub.status.busy": "2025-01-16T13:48:15.584748Z",
     "iopub.status.idle": "2025-01-16T13:48:15.622988Z",
     "shell.execute_reply": "2025-01-16T13:48:15.622091Z",
     "shell.execute_reply.started": "2025-01-16T13:48:15.585063Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train logistic regression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:48:21.774859Z",
     "iopub.status.busy": "2025-01-16T13:48:21.774564Z",
     "iopub.status.idle": "2025-01-16T13:48:21.806728Z",
     "shell.execute_reply": "2025-01-16T13:48:21.805980Z",
     "shell.execute_reply.started": "2025-01-16T13:48:21.774837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'This product is awesome!' -> Sentiment: positive\n",
      "Sentence: 'I regret buying this, such a disappointment.' -> Sentiment: positive\n",
      "Sentence: 'What a wonderful day.' -> Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "new_sentences = [\n",
    "    \"This product is awesome!\",\n",
    "    \"I regret buying this, such a disappointment.\",\n",
    "    \"What a wonderful day.\"\n",
    "]\n",
    "\n",
    "for sentence in new_sentences:\n",
    "    vector = nlp(sentence).vector\n",
    "    prediction = clf.predict([vector])\n",
    "    sentiment = \"positive\" if prediction[0] == 1 else \"negative\"\n",
    "    print(f\"Sentence: '{sentence}' -> Sentiment: {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load Yelp polarity dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myelp_polarity\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# dataset = load_dataset(\"amazon_polarity\")\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Split into train and test sets\u001b[39;00m\n\u001b[1;32m      6\u001b[0m train_data \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Load Yelp polarity dataset\n",
    "dataset = load_dataset(\"yelp_polarity\")\n",
    "# dataset = load_dataset(\"amazon_polarity\")\n",
    "\n",
    "# Split into train and test sets\n",
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
