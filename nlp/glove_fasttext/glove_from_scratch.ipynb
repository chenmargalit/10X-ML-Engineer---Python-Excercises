{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simple terms: The model learns vector representations for words by predicting their co-occurrence relationships as described by the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "J = \\sum_{i,j} f(X_{ij}) \\left( w_i^\\top w_j + b_i + b_j - \\log X_{ij} \\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gap between the prediction and the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left( w_i^\\top w_j + b_i + b_j - \\log X_{ij} \\right)^2\n",
    "$$"
   ]
  },
  {
   "attachments": {
    "3d0acdb9-5834-4e2b-ba0e-792c52f268a3.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:3d0acdb9-5834-4e2b-ba0e-792c52f268a3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighting function that adjusts how much importance is given to each word pair (i,j) based on their co-occurrence frequency. The calculation is the amount of co-occurence / some hyperparameter (typically 10). The result is raised to the power of another hyper parameter, typically 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Xmax -  limits the impact of very frequent co-occurrences, preventing them from dominating trainingabs\n",
    "* alpha - balances the scaling of weights, giving less frequent pairs a fair impact without overemphasizing rare ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(X_{ij})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/chen.m/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/chen.m/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"gutenberg\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    sentence = \" \".join(sentence).lower()  # Lowercase\n",
    "    sentence = re.sub(r\"[^a-z\\s]\", \"\", sentence)  # Remove punctuation\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "corpus = nltk.corpus.gutenberg.sents(\"austen-emma.txt\")\n",
    "\n",
    "corpus = [preprocess(sentence) for sentence in corpus]\n",
    "tokenized_corpus = [sentence.split() for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    sentence = \" \".join(sentence).lower()  # Lowercase\n",
    "    sentence = re.sub(r\"[^a-z\\s]\", \"\", sentence)  # Remove punctuation\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' emma by jane austen  '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(word for sentence in tokenized_corpus for word in sentence)\n",
    "vocab_size = len(vocab)\n",
    "word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx_to_word = {idx: word for word, idx in word_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 867 ms, sys: 44.6 ms, total: 911 ms\n",
      "Wall time: 929 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build the co-occurrence matrix\n",
    "window_size = 2\n",
    "co_occurrence_matrix = np.zeros((vocab_size, vocab_size), dtype=np.float32)\n",
    "\n",
    "for sentence in tokenized_corpus:\n",
    "    for idx, word in enumerate(sentence):\n",
    "        word_idx = word_to_idx[word]\n",
    "        start = max(idx - window_size, 0)\n",
    "        end = min(idx + window_size + 1, len(sentence))\n",
    "        for context_word in sentence[start:end]:\n",
    "            if context_word != word:\n",
    "                context_idx = word_to_idx[context_word]\n",
    "                co_occurrence_matrix[word_idx, context_idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-occurrence matrix shape: (7096, 7096)\n"
     ]
    }
   ],
   "source": [
    "print(\"Co-occurrence matrix shape:\", co_occurrence_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(co_occurrence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' emma by jane austen  '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7752"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloVe(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(GloVe, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.word_biases = nn.Embedding(vocab_size, 1)\n",
    "        self.context_biases = nn.Embedding(vocab_size, 1)\n",
    "\n",
    "        # Initialize weights\n",
    "        # nn.init.xavier_uniform_(self.word_embeddings.weight)\n",
    "        # nn.init.xavier_uniform_(self.context_embeddings.weight)\n",
    "        # nn.init.zeros_(self.word_biases.weight)\n",
    "        # nn.init.zeros_(self.context_biases.weight)\n",
    "\n",
    "    def forward(self, word_idx, context_idx):\n",
    "        word_embed = self.word_embeddings(word_idx)\n",
    "        context_embed = self.context_embeddings(context_idx)\n",
    "        word_bias = self.word_biases(word_idx).squeeze()\n",
    "        context_bias = self.context_biases(context_idx).squeeze()\n",
    "        \n",
    "        # Dot product + biases\n",
    "        prediction = (word_embed * context_embed).sum(dim=1) + word_bias + context_bias\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloVe(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(GloVe, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.word_biases = nn.Embedding(vocab_size, 1)\n",
    "        self.context_biases = nn.Embedding(vocab_size, 1)\n",
    "\n",
    "        # Initialize weights\n",
    "        nn.init.uniform_(self.word_embeddings.weight, a=-0.5, b=0.5)  \n",
    "        nn.init.uniform_(self.context_embeddings.weight, a=-0.5, b=0.5)\n",
    "        nn.init.zeros_(self.word_biases.weight)\n",
    "        nn.init.zeros_(self.context_biases.weight)\n",
    "\n",
    "    def forward(self, word_idx, context_idx):\n",
    "        word_embed = self.word_embeddings(word_idx)\n",
    "        context_embed = self.context_embeddings(context_idx)\n",
    "        word_bias = self.word_biases(word_idx).squeeze()\n",
    "        context_bias = self.context_biases(context_idx).squeeze()\n",
    "        \n",
    "        # Dot product + biases\n",
    "        prediction = (word_embed * context_embed).sum(dim=1) + word_bias + context_bias\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighting_function(x, X_max=100, alpha=0.75):\n",
    "    return torch.where(x < X_max, (x / X_max) ** alpha, torch.ones_like(x))\n",
    "\n",
    "def glove_loss(prediction, log_co_occurrence, weights):\n",
    "    return torch.sum(weights * (prediction - log_co_occurrence) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_occurrence = torch.tensor(co_occurrence_matrix, dtype=torch.float32, device=device)\n",
    "log_co_occurrence = torch.log(co_occurrence + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nonzero is a PyTorch function that returns the indices of all non-zero elements in a tensor.\n",
    "word_indices, context_indices = torch.nonzero(co_occurrence, as_tuple=True)\n",
    "co_occurrence_values = co_occurrence[word_indices, context_indices]\n",
    "weights = weighting_function(co_occurrence_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and optimizer\n",
    "embedding_dim = 100\n",
    "model = GloVe(vocab_size, embedding_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 30041.3711\n",
      "Epoch 20, Loss: 6967.3604\n",
      "Epoch 30, Loss: 3525.5100\n",
      "Epoch 40, Loss: 2237.3035\n",
      "Epoch 50, Loss: 1345.7761\n",
      "Epoch 60, Loss: 1012.4763\n",
      "Epoch 70, Loss: 797.9583\n",
      "Epoch 80, Loss: 659.7769\n",
      "Epoch 90, Loss: 559.8011\n",
      "Epoch 100, Loss: 484.2773\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    predictions = model(word_indices, context_indices)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = glove_loss(predictions, log_co_occurrence[word_indices, context_indices], weights)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Similarities:\n",
      "Similarity between 'king' and 'queen': -0.0300\n",
      "Similarity between 'man' and 'woman': 0.4201\n",
      "Words 'deep' or 'learning' not in vocabulary.\n",
      "Words 'fun' or 'amazing' not in vocabulary.\n"
     ]
    }
   ],
   "source": [
    "# Extract embeddings\n",
    "word_embeddings = model.word_embeddings.weight.detach().cpu().numpy()\n",
    "\n",
    "# Cosine similarity function\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Test pairs\n",
    "test_pairs = [(\"king\", \"queen\"), (\"man\", \"woman\"), (\"deep\", \"learning\"), (\"fun\", \"amazing\")]\n",
    "\n",
    "print(\"\\nCosine Similarities:\")\n",
    "for word1, word2 in test_pairs:\n",
    "    if word1 in word_to_idx and word2 in word_to_idx:\n",
    "        vec1 = word_embeddings[word_to_idx[word1]]\n",
    "        vec2 = word_embeddings[word_to_idx[word2]]\n",
    "        sim = cosine_similarity(vec1, vec2)\n",
    "        print(f\"Similarity between '{word1}' and '{word2}': {sim:.4f}\")\n",
    "    else:\n",
    "        print(f\"Words '{word1}' or '{word2}' not in vocabulary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Similarities:\n",
      "Similarity between 'king' and 'queen': -0.0300\n",
      "Similarity between 'man' and 'woman': 0.4201\n",
      "Words 'deep' or 'learning' not in vocabulary.\n",
      "Words 'fun' or 'amazing' not in vocabulary.\n"
     ]
    }
   ],
   "source": [
    "# Extract embeddings\n",
    "word_embeddings = model.word_embeddings.weight.detach().cpu().numpy()\n",
    "\n",
    "# Cosine similarity function\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Test pairs\n",
    "test_pairs = [(\"king\", \"queen\"), (\"man\", \"woman\"), (\"deep\", \"learning\"), (\"fun\", \"amazing\")]\n",
    "\n",
    "print(\"\\nCosine Similarities:\")\n",
    "for word1, word2 in test_pairs:\n",
    "    if word1 in word_to_idx and word2 in word_to_idx:\n",
    "        vec1 = word_embeddings[word_to_idx[word1]]\n",
    "        vec2 = word_embeddings[word_to_idx[word2]]\n",
    "        sim = cosine_similarity(vec1, vec2)\n",
    "        print(f\"Similarity between '{word1}' and '{word2}': {sim:.4f}\")\n",
    "    else:\n",
    "        print(f\"Words '{word1}' or '{word2}' not in vocabulary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine Similarities:\n",
      "Similarity between 'king' and 'queen': -0.0300\n",
      "Similarity between 'man' and 'woman': 0.4201\n"
     ]
    }
   ],
   "source": [
    "# Extract embeddings\n",
    "word_embeddings = model.word_embeddings.weight.detach().cpu().numpy()\n",
    "\n",
    "# Cosine similarity function\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Test pairs\n",
    "test_pairs = [(\"king\", \"queen\"), (\"man\", \"woman\")]\n",
    "\n",
    "print(\"\\nCosine Similarities:\")\n",
    "for word1, word2 in test_pairs:\n",
    "    if word1 in word_to_idx and word2 in word_to_idx:\n",
    "        vec1 = word_embeddings[word_to_idx[word1]]\n",
    "        vec2 = word_embeddings[word_to_idx[word2]]\n",
    "        sim = cosine_similarity(vec1, vec2)\n",
    "        print(f\"Similarity between '{word1}' and '{word2}': {sim:.4f}\")\n",
    "    else:\n",
    "        print(f\"Words '{word1}' or '{word2}' not in vocabulary.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{|c|c|c|}\n",
    "\\hline\n",
    "\\textbf{Aspect} & \\textbf{GloVe} & \\textbf{Word2Vec} \\\\\n",
    "\\hline\n",
    "\\textbf{Training Approach} & \\text{Uses a co-occurrence matrix and matrix factorization.} & \\text{Predictive model using CBOW or Skip-Gram.} \\\\\n",
    "\\hline\n",
    "\\textbf{Data Utilization} & \\text{Leverages entire corpus statistics for global context.} & \\text{Processes word pairs iteratively in local contexts.} \\\\\n",
    "\\hline\n",
    "\\textbf{Training Efficiency} & \\text{Slower due to large co-occurrence matrix decomposition.} & \\text{Faster with a simpler predictive model.} \\\\\n",
    "\\hline\n",
    "\\textbf{Representation} & \\text{Captures global semantic relationships.} & \\text{Focuses on local contextual similarities.} \\\\\n",
    "\\hline\n",
    "\\textbf{Memory Usage} & \\text{Requires more memory for storing a co-occurrence matrix.} & \\text{Less memory-intensive with dynamic processing.} \\\\\n",
    "\\hline\n",
    "\\textbf{Performance} & \\text{Excels in analogy and word similarity tasks.} & \\text{Captures context-specific meanings better.} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:49:37.714727Z",
     "iopub.status.busy": "2025-01-16T13:49:37.714423Z",
     "iopub.status.idle": "2025-01-16T13:49:37.718082Z",
     "shell.execute_reply": "2025-01-16T13:49:37.717232Z",
     "shell.execute_reply.started": "2025-01-16T13:49:37.714705Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_md'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the English medium model with word vectors\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men_core_web_md\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Access word vectors\u001b[39;00m\n\u001b[1;32m      7\u001b[0m movie_vector \u001b[38;5;241m=\u001b[39m nlp(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mvector\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/spacy/__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     31\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     38\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/spacy/util.py:449\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_md'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English medium model with word vectors\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "# Access word vectors\n",
    "movie_vector = nlp('movie').vector\n",
    "print(movie_vector)  # GloVe-like embedding for \"movie\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:47:59.697453Z",
     "iopub.status.busy": "2025-01-16T13:47:59.697101Z",
     "iopub.status.idle": "2025-01-16T13:47:59.701436Z",
     "shell.execute_reply": "2025-01-16T13:47:59.700613Z",
     "shell.execute_reply.started": "2025-01-16T13:47:59.697424Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    (\"I love this movie!\", \"positive\"),\n",
    "    (\"This is the worst film I’ve ever seen.\", \"negative\"),\n",
    "    (\"Absolutely fantastic experience.\", \"positive\"),\n",
    "    (\"I hated it. Total waste of time.\", \"negative\"),\n",
    "    (\"The plot was amazing and I enjoyed it a lot.\", \"positive\"),\n",
    "    (\"Terrible acting and boring story.\", \"negative\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:48:01.475364Z",
     "iopub.status.busy": "2025-01-16T13:48:01.475054Z",
     "iopub.status.idle": "2025-01-16T13:48:01.530555Z",
     "shell.execute_reply": "2025-01-16T13:48:01.529852Z",
     "shell.execute_reply.started": "2025-01-16T13:48:01.475342Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create features (vectors) and labels\n",
    "X = [nlp(text).vector for text, label in data]\n",
    "y = [1 if label == \"positive\" else 0 for _, label in data] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:50:03.466107Z",
     "iopub.status.busy": "2025-01-16T13:50:03.465769Z",
     "iopub.status.idle": "2025-01-16T13:50:03.470118Z",
     "shell.execute_reply": "2025-01-16T13:50:03.469075Z",
     "shell.execute_reply.started": "2025-01-16T13:50:03.466080Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T13:50:09.691113Z",
     "iopub.status.busy": "2025-01-16T13:50:09.690780Z",
     "iopub.status.idle": "2025-01-16T13:50:17.473890Z",
     "shell.execute_reply": "2025-01-16T13:50:17.473189Z",
     "shell.execute_reply.started": "2025-01-16T13:50:09.691086Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5741776e332f49a4b44aa85de6c4f9f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.93k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6b15315ae74d22ba9c4d1e91e59ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70edd1288149445a905474a8f363798b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/17.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577dbd4ad7b5440bbdd4c0d561e34aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/560000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd49ad0a0ab456f9b30a736d66c3792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/38000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.\", 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "# Load Yelp polarity dataset\n",
    "dataset = load_dataset(\"yelp_polarity\")\n",
    "# dataset = load_dataset(\"amazon_polarity\")\n",
    "\n",
    "# Split into train and test sets\n",
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"]\n",
    "\n",
    "# Print an example\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the data in the right format, put it into some classifier. Try a few different models, see what works best\n",
    "\n",
    "If you have the time, try building a neural network that does the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
